fil = new Array();
fil["0"]= "welcome.html@@@Welcome to Platfora@@@Welcome to Platfora™ — an end-to-end data processing and analytics platform for discovering, exploring, analyzing, and sharing data that originates in Hadoop. To learn more about Platfora, see...";
fil["1"]= "data_analysis/analyze_data_top.html@@@Analyze Data@@@Vizboards is the business intelligence (BI) and data analytics area of Platfora. Once you have pulled data into Platfora by creating a lens, you can explore and interact with the data using Platfora s visualization builder tools. To begin analyzing data, you first create a project document called a vizboard. A vizboard is a container for one or more visualizations...";
fil["2"]= "data_analysis/adhoc_analysis/change_field_labels_width.html@@@Change Field Labels Width in a Viz@@@When you add a dimension field to your visualization, the field name and its values are assigned a width by default. Platfora calculates a best guess width based on several factors including the length of the current values in the field. However, you can define the width assigned the labels of fields used in a drop-zone...";
fil["3"]= "data_analysis/adhoc_analysis/choose_analysis_type.html@@@Choose the Analysis Type@@@Every visualization performs one type of analysis, such as ad hoc (chart or cross-tab) or funnel. The analysis type determines the type of lenses available for the viz, such as aggregate or event series lenses. Choosing an analysis type shows all datasets that have lenses of the appropriate type built from the focal point of that dataset...";
fil["4"]= "data_analysis/adhoc_analysis/crosstab_totals.html@@@Enable Cross-Tab Totals@@@Cross-Tab view can be enabled to show totals for the data in columns and rows. For example, if each row shows the sum of orders, then turning on totals for rows creates a column showing the sum of all orders in each row...";
fil["5"]= "data_analysis/adhoc_analysis/marktype_area.html@@@Use Area Marks@@@Similar to a line graph, an area graph displays quantitative (measure) data over a continuum (such as time), and is typically used to compare two or more quantities. However, unlike lines, area charts are typically used to represent cumulated totals rather than individual totals. An area chart shows the space between marks filled in with color, which is helpful for showing how the member of a dimension is contributing to an overall trend...";
fil["6"]= "data_analysis/adhoc_analysis/marktype_bar.html@@@Use Bar Marks@@@Bars are useful for comparing quantitative data by different categorical groupings. Bar is the default mark choice when you are analyzing a single measure across one or more dimensions, such as comparing sales totals by region...";
fil["7"]= "data_analysis/adhoc_analysis/marktype_line.html@@@Use Line Marks@@@A line chart displays a series of individual quantitative (measure) data points connected by line segments. A line chart is often used to visualize a trend in measure data over intervals of time (time series data) with the line drawn chronologically. Line is the default mark choice when you are analyzing a measure across a date or a numeric (quantitative) dimension...";
fil["8"]= "data_analysis/adhoc_analysis/marktype_path.html@@@Using Path Marks@@@A path connects data points with lines. However, unlike the line chart type, the data points are connected in order. Paths are useful for showing data that follows a natural order, such as ordered stops on a road trip over, or ordered web page visits over time...";
fil["9"]= "data_analysis/adhoc_analysis/marktype_point.html@@@Use Point Marks@@@The point mark type is best used to show the relationship between two independent variables, and is most often used for building scatterplot charts or bubble charts. Point is the default mark type when you select a measure for both the X-axis and Y-axis, and place a dimension in color, opacity, or size...";
fil["10"]= "data_analysis/adhoc_analysis/marktype_polygon.html@@@Using Polygon Marks@@@A polygon mark is similar to a path mark, except that the connected lines are filled in as shaded areas. The polygon chart type is useful when you have areas of data points on your visualization that you want to shade in to see distinct areas of data. Polygon charts typically require special datasets to effectively convert useful insights, and are not used that often in the current product. This mark type will be more useful in the future when Platfora has support for maps...";
fil["11"]= "data_analysis/adhoc_analysis/truncate_field_labels.html@@@Truncate Field Labels in a Viz@@@When dimension field values are really long, the field name and value labels in a visualization are truncated on the right side by default. However, you can configure where to truncate text for fields used in a drop-zone...";
fil["12"]= "data_analysis/adhoc_analysis/viz_about_crosstabs.html@@@About Cross-Tab View@@@If you want to see the data comprising the points on a visualization, you can toggle the viz to Cross-Tab view. This shows the data in tabular, spreadsheet format...";
fil["13"]= "data_analysis/adhoc_analysis/viz_about_dropzones.html@@@About the Builder Drop Zones@@@Dragging fields to the Builder drop zones determine the placement and visual appearance of the marks on your visualization...";
fil["14"]= "data_analysis/adhoc_analysis/viz_about_field_roles.html@@@About Lens Field Types and Roles@@@Lens fields are categorized into two basic roles: measures and dimensions. Measures are always aggregated numeric type data. Dimensions can be numeric, text, or datetime type data. As you browse through the fields in the data panel, you will notice that each field has an icon to denote its role and type...";
fil["15"]= "data_analysis/adhoc_analysis/viz_about_viz_menu.html@@@About the Viz Menus@@@Every visualization has a collection of buttons in its top right corner. These viz controls include options for duplicating, resizing, and exporting the visualization. There is also menu controls for creating and viewing viz comments, and for managing viz selections...";
fil["16"]= "data_analysis/adhoc_analysis/viz_about_workspace.html@@@About the Ad Hoc Analysis Viz Workspace@@@When you edit an ad hoc analysis visualization within a vizboard, the Builder panels contain the tools you need to build the visualization. The control panels on the left-hand side of the workspace are used to select lens data and design the visual representation of the data. The control panels on the right-hand side of the viz workspace show the data filters and appearance-encoding legends that are active in the selected visualization...";
fil["17"]= "data_analysis/adhoc_analysis/viz_add_marks.html@@@Add Marks to a Viz@@@The initial marks on a visualization are determined by the dimension and measure combinations used on the axes (X-axis and Y-axis). You can add additional marks (or groups) to the visualization by adding additional dimensions to the Details drop zone, or by adding additional dimensions to the Color, Shape, or Labels encoding drop zones...";
fil["18"]= "data_analysis/adhoc_analysis/viz_axis_change_range.html@@@Change the Value Range of a Measure Axis@@@By default, the range of values shown on a measure axis always includes 0 (zero) in the range. For data that has a range skewed to high values, you may not want the measure axis to start at zero. For example, if your data values start at 1,000,000 and go to 10,000,000 then you may want the measure axis to reflect the actual range of values rather than starting at...";
fil["19"]= "data_analysis/adhoc_analysis/viz_axis_change_scale.html@@@Change the Scale of a Measure Axis@@@When you have a measure field in the axis drop zones (X-axis or Y-axis), the corresponding axis shows a numeric scale depicting the range of values for the selected measure. By default, measure axes show a Linear scale of numeric values from lowest to highest. You can change a measure axis to display values on a Logarithmic scale or a Percent of Total scale...";
fil["20"]= "data_analysis/adhoc_analysis/viz_axis_controls.html@@@Control the Axes of a Viz@@@Visualizations use a grid layout of columns and rows. Fields added to the X-axis drop-zone show on the horizontal axis (equivalent to columns), and fields added to the Y-axis drop-zone show on the vertical axis (equivalent to rows). The axes have headers that display the field names, and labels denoting the field values (or members...";
fil["21"]= "data_analysis/adhoc_analysis/viz_axis_dimension_options.html@@@Changing Axis Options for Dimension Data@@@When you have a dimension field in the X-axis or Y-axis drop zone, the corresponding axis shows the labels of the dimension values. You can change the sort order of a dimension axis, limit the number of values shown on the axis, or toggle the axis type to display values on a categorical or quantitative scale...";
fil["22"]= "data_analysis/adhoc_analysis/viz_axis_dimension_sort.html@@@Change the Sort Order of a Dimension Axis@@@Changing the sort order of a dimension axis rearranges the order of the marks on the viz. You can change the default sort order of a dimension, sort the dimension marks on the viz according to the value of a measure, or limit the number of dimension values shown in the viz...";
fil["23"]= "data_analysis/adhoc_analysis/viz_axis_dimension_types.html@@@Change the Type of a Dimension Axis@@@When you have a dimension field in a X-axis or Y-axis drop-zone, the default axis type is categorical (discrete). This means that the values are shown as individual members or categories. For dimension fields that contain numeric or datetime type data, you can change the axis type to a quantitative scale (continuous) axis instead...";
fil["24"]= "data_analysis/adhoc_analysis/viz_axis_field_order.html@@@Use Multiple Fields on an Axis@@@The X-axis and Y-axis drop zones can contain multiple fields. Adding additional measures to an axis produces a dual or trellised axis. Adding additional dimensions to an axis produces a grouped axis...";
fil["25"]= "data_analysis/adhoc_analysis/viz_axis_measure_formatting.html@@@Change the Number Formatting of a Measure@@@You can specify the number format for the measure values shown in the viz and cross-tab text. You can select from a set of standard formats, such as normal, currency, scientific, and percentage...";
fil["26"]= "data_analysis/adhoc_analysis/viz_axis_measure_options.html@@@Change Axis Options for Measure Data@@@Measure fields represent the quantitative data in your viz, and always contain aggregated numeric type data. When you place a measure field in the X-axis or Y-axis drop-zone, you get a quantitative (or continuous) axis. You can change various display options of a measure axis such as the display name formatting, value range, the scale, or the number formatting...";
fil["27"]= "data_analysis/adhoc_analysis/viz_axis_transpose.html@@@Transpose the X and Y Axis@@@You can transpose the X and Y axis of a visualization by clicking Swap underneath the X-axis drop zone in the Builder panel. This swaps the fields in the X-axis drop zone with those in the Y-axis drop zone, thereby flipping the orientation of your viz...";
fil["28"]= "data_analysis/adhoc_analysis/viz_choose_lens.html@@@Choose a Lens@@@Every visualization must be associated with a lens. To find a lens, first select the dataset you are interested in. Only datasets that have successfully built lenses will be shown. Choosing a dataset will show any lenses that have been built from the focal point of that dataset...";
fil["29"]= "data_analysis/adhoc_analysis/viz_data_lineage.html@@@View the Data Lineage of a Field@@@Preparing data for analysis often involves some form of cleansing and manipulation in order to make sense of the data. Raw source data is seldom consumed in its original format, and usually goes through various processing and transformation steps before it is used in a visualization. Viewing the data lineage of a field allows you to see where the data came from and what processing functions were applied...";
fil["30"]= "data_analysis/adhoc_analysis/viz_data_panel.html@@@Choosing Data to Analyze@@@The first step in creating an ad hoc visualization is choosing the data you want to explore and analyze, which is done by selecting a lens. Once you pick a lens to work with, the measure and dimension fields in that lens are loaded into the lens field list in the data panel...";
fil["31"]= "data_analysis/adhoc_analysis/viz_drag_fields.html@@@Drag Fields to Builder Drop Zones@@@To begin building a visualization, drag fields from the data panel into one of the Builder drop zones. A good way to get started is to think of your business question and drag the associated fields to the X-axis and Y-axis drop zones. For example, if your question was  How much did we sell from each product line?  you could start by dragging the Product Line dimension to X-axis and the Total Sales measure to Y-axis...";
fil["32"]= "data_analysis/adhoc_analysis/viz_explore_marks.html@@@Exploring Marks in a Viz@@@The Platfora vizboard has a number of tools for exploring individual marks (data points) or sets of marks in a viz. You can select or highlight marks, hover over a mark to see its data details, or pan and zoom to focus on a particular area of marks in a viz...";
fil["33"]= "data_analysis/adhoc_analysis/viz_field_display_name.html@@@Change Field Display Names on an Axis@@@When you add a field to your visualization, the field name is displayed in the viz axis headers. By default, the field name shown in a viz is the same as it appears in the lens. You can change the display name of any field used in a visualization on a per-viz basis...";
fil["34"]= "data_analysis/adhoc_analysis/viz_field_options_top.html@@@Control Field Labels in a Viz@@@Platfora allows you to control how field names, labels, and values appear on the axis of a viz...";
fil["35"]= "data_analysis/adhoc_analysis/viz_filter_by_field.html@@@Add a Filter on a Field@@@Filtering on a field allows you to include or exclude records from the visualization based on the values of the selected field. The filter controls differ depending on the type of field you are filtering on (dimension, measure, or date...";
fil["36"]= "data_analysis/adhoc_analysis/viz_filter_by_limit.html@@@Filter by Limit@@@Another way to filter a dimension field is to apply a limit on the number of dimension members appearing in the visualization. You can also use limit in combination with a sort to limit a dimension based on a measure calculation. For example, if you wanted to filter products to only show the top 10 sellers, you could sort the products dimension by the total sales measure, and then limit the results by 1...";
fil["37"]= "data_analysis/adhoc_analysis/viz_filter_by_selection.html@@@Filter by Selection@@@While working in a visualization, you can isolate particular marks on the visualization by selecting them. You can then save your selection as an inclusive or exclusive filter. Saved selection filters are saved in the Filters panel of the visualization workspace...";
fil["38"]= "data_analysis/adhoc_analysis/viz_filter_date.html@@@Filter on Date Fields@@@Date fields are a special kind of dimension that allow for either range or relative filters. A date range filter allows you to select a range of days to include or exclude. A relative date filter allows you to pick a particular date and then choose the day, week, month, quarter, or year prior to, following, containing, or up to that date. Note that date filters only apply to Date or Date (Time Series) fields. Other date-related fields (Month, Week, Year, and so on) are treated just like any other dimension field...";
fil["39"]= "data_analysis/adhoc_analysis/viz_filter_dimension.html@@@Filter on Dimension Fields@@@Dimension fields can contain textual or numeric data, so filtering on a dimension depends on the data type of the selected field. Category filters allow you to select specific dimension members (values) to include or exclude in your visualization. Range filters allow you to choose a range of values to include or exclude, and are only applicable to dimensions that contain numeric dat...";
fil["40"]= "data_analysis/adhoc_analysis/viz_filter_exclude_mode.html@@@Toggling Filter Include/Exclude Mode@@@By default, filters are inclusive, meaning the values selected in the filter are included in the visualization. You can change a filter to be exclusive, meaning everything except the selected values are included in the visualization. Exclusive mode is useful if you have a long list of values, and there are only a couple of values you want to filter out...";
fil["41"]= "data_analysis/adhoc_analysis/viz_filter_global_mode.html@@@Designate Page Filters@@@Designating a page filter allows you to filter multiple visualizations at once (provided they all contain the same field). For example, if you designate a page filter on a Date field in one visualization, then any other visualization on the same vizboard page that uses Date will have that filter applied as well...";
fil["42"]= "data_analysis/adhoc_analysis/viz_filter_measure.html@@@Filter on a Measure Fields@@@Measures always contain quantitative data, so filtering on a measure involves choosing a range of numeric values to include or exclude in your visualization. In Platfora, measures are always the result of an aggregate calculation on a group of dimension values, so the visual rendering of a measure filter changes depending on the dimension fields and filters used in the visualization...";
fil["43"]= "data_analysis/adhoc_analysis/viz_filter_remove.html@@@Remove a Filter@@@You can remove a filter on a field by deleting the field from the Filters panel of the visualization editor workspace. Note that limit filters do not show in the Filters panel. To remove a limit filter on a dimension, you need to open the Sort dialog on the particular dimension field to remove any limits that have been applied...";
fil["44"]= "data_analysis/adhoc_analysis/viz_filters.html@@@Filtering Viz Data@@@Adding a filter to a visualization allows you to constrain the data that is shown in the visualization. You can add a filter using a particular field, or by selecting and isolating a set of marks on a viz...";
fil["45"]= "data_analysis/adhoc_analysis/viz_find_lens_fields.html@@@Find Fields in a Lens@@@When you pick a lens to work with, the measure and dimension fields included in the lens are shown in the lens data panel. The data panel does not show all of the dataset fields, only those that were requested when the lens was built...";
fil["46"]= "data_analysis/adhoc_analysis/viz_hide_field_names.html@@@Hide Field Name and Values on a Chart Axis@@@When you add a field to your visualization, the field name and its values are displayed in the viz axis headers. To save space in a viz, you can hide the field name or its values on the axis of a chart viz on a per-viz basis...";
fil["47"]= "data_analysis/adhoc_analysis/viz_histogram.html@@@Creating a Histogram@@@Marks on a Bar chart are separated by empty space by default. This section describes how to change a bar chart to a histogram (no space between bars...";
fil["48"]= "data_analysis/adhoc_analysis/viz_mark_appearance.html@@@Adjusting Mark Appearance@@@Dragging a field into one of the Marks drop zones of the Builder panel is one way to add marks to a visualization and visually encode their appearance, but you can also use the pull-out menus to change the visual appearance of marks already on the visualization without adding additional groupings...";
fil["49"]= "data_analysis/adhoc_analysis/viz_mark_appearance_color.html@@@Adjusting Mark Color@@@Viz marks can be colored in a single color or a collection of colors, depending on how the data is encoded in the viz...";
fil["50"]= "data_analysis/adhoc_analysis/viz_mark_appearance_labels.html@@@Adjust Mark Labels@@@Viz marks can be displayed with or without a label representing one of different values associated with each mark...";
fil["51"]= "data_analysis/adhoc_analysis/viz_mark_appearance_opacity.html@@@Adjust Mark Opacity@@@Viz marks can appear as a single opacity or range of opacities, depending on how the data is encoded in the viz...";
fil["52"]= "data_analysis/adhoc_analysis/viz_mark_appearance_options.html@@@Change Mark Appearance Options@@@Visualization mark appearances can be changed by color, size, opacity, shape, and label text. You can also increase the number of appearance controls to more finely tune the appearance of a viz. This allows you to increase the data density of a viz through mark appearance...";
fil["53"]= "data_analysis/adhoc_analysis/viz_mark_appearance_shape.html@@@Adjust Mark Shape@@@Viz marks can be colored in a single shape or a collection of shapes, depending on how the data is encoded in the viz...";
fil["54"]= "data_analysis/adhoc_analysis/viz_mark_appearance_size.html@@@Adjusting Mark Size@@@Viz marks can appear as a single size or range of sizes, depending on how the data is encoded in the viz...";
fil["55"]= "data_analysis/adhoc_analysis/viz_mark_controls.html@@@Controlling the Marks on a Viz@@@A mark is a graphical symbol (point, area, line, and so on) used to encode data in a visualization. In Platfora, a mark is the visual representation of a measure value calculated for a group of input records or rows. A group consists of records that share the same value for the dimension(s) used in the visualization. For example, if you picked fields called Region (a dimension) and Units Sold (a measure) in your viz, then there would be a mark on your viz for each region depicting the total number of units sold in that region (North America=5000, Europe=3000, Asia=7000, etc...";
fil["56"]= "data_analysis/adhoc_analysis/viz_mark_types.html@@@About Mark Types@@@The mark type controls the shape of the data on the visualization and how data points are visually represented. Setting the mark type to Auto (the default) will automatically choose the best visual representation of your data based on the fields you have selected...";
fil["57"]= "data_analysis/adhoc_analysis/viz_marks_pan_zoom.html@@@Zoom and Pan in a Viz@@@A visualization (viz) fits into a fixed-size panel on a vizboard page, and is always rendered at 100% scale. To explore different areas of a viz in more detail, you can use the viz pan and zoom controls. The viz view size always re-adjusts to 100% when you change the viz definition, exit the vizboard, or switch between pages...";
fil["58"]= "data_analysis/adhoc_analysis/viz_marks_select.html@@@Select and Highlighting Marks on a Viz@@@While working in a visualization, you can isolate particular marks on the visualization by selecting or highlighting them. The selection applies to all marks on a vizboard page that share the same dimension group. For example, if you have two visualizations on a page that were created using the same lens data, highlighting a mark in one will also highlight related marks in other visualizations on the same page...";
fil["59"]= "data_analysis/adhoc_analysis/viz_marks_tooltips.html@@@View the Data Values for a Mark@@@You can hover your mouse over any mark in a viz to see the data values that comprise that mark. The measure value(s) for the dimension group represented by the mark are shown in a tooltip...";
fil["60"]= "data_analysis/adhoc_analysis/viz_solid_shapes.html@@@Create Solid Shapes@@@Marks on a Point chart appear as hollow shapes by default. This section describes how to change the marks to solid shapes...";
fil["61"]= "data_analysis/adhoc_analysis/viz_top.html@@@Build Ad Hoc Visualizations@@@Ad Hoc visualizations allow you to do exploratory analysis of aggregate data in either chart or tabular (cross-tab) form. Visualizations appear inside panels (or boxes) in the workspace area of a vizboard page. A new vizboard page will always have one empty placeholder visualization to get you started...";
fil["62"]= "data_analysis/adhoc_analysis/viz_what_is_a_viz.html@@@What is a Visualization (Viz)?@@@A visualization (or viz for short) is a graphical representation of certain data fields chosen from the perspective of a Platfora lens. It is a query of aggregated lens data that is visually rendered based on the types of fields chosen (measure or dimension), their order and placement in the Builder drop zones, and the various appearance encodings applied to the data (color, size, shape, and so on...";
fil["63"]= "data_analysis/adhoc_analysis/viz_what_is_a_viz_query.html@@@What is a Viz Query?@@@When you build a visualization in Platfora, you are actually creating queries. The act of dragging a lens field to a Builder drop zone creates a query that is sent to the Platfora server, fetches the requested lens data, and then visually renders the results as a Chart or graph. You can also see the results in a tabular, spreadsheet format by looking at the Cross-Tab of a viz...";
fil["64"]= "data_analysis/chart_types/bar_color.html@@@Chart Type: Bars with Different Color Values@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Measure Details Color Measure Size Opacity Shape Labels...";
fil["65"]= "data_analysis/chart_types/bar_simple.html@@@Chart Type: Simple Bar@@@A bar chart is useful for recording discrete categories of data. Bar graphs can also be used for more complex comparisons of data with grouped bar charts and stacked bar charts...";
fil["66"]= "data_analysis/chart_types/bar_split_with_values.html@@@Chart Type: Split Bar with Values@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Measure Details Dimension Color Measure Size Opacity Shape Labels...";
fil["67"]= "data_analysis/chart_types/bar_stacked.html@@@Chart Type: Stacked Bar@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Measure Details Color Dimension Size Opacity Shape Labels...";
fil["68"]= "data_analysis/chart_types/bar_variable_widths.html@@@Chart Type: Bar with Variable Widths@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Measure Details Color Size Measure Opacity Shape Labels...";
fil["69"]= "data_analysis/chart_types/dot_plot.html@@@Chart Type: Dot Plot@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Measure Details Color Size Opacity Shape Dimension Labels...";
fil["70"]= "data_analysis/chart_types/matrix_heatmap.html@@@Chart Type: Heatmap@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Dimension Details Color Measure Size Opacity Shape Labels...";
fil["71"]= "data_analysis/chart_types/matrix_heatmap_size.html@@@Chart Type: Size Encoded Heatmap@@@Mark Type: Bar (not Auto) Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Dimension Details Color Dimension Size Measure Opacity Shape Labels...";
fil["72"]= "data_analysis/chart_types/matrix_size.html@@@Chart Type: Size Encoded Matrix@@@Mark Type: Bar (not Auto) Table 1. Chart Type Recipe Drop Zone Field Type X-axis Dimension Y-axis Dimension Details Color Size Measure Opacity Shape Labels...";
fil["73"]= "data_analysis/chart_types/plot_bubblechart.html@@@Chart Type: Bubble Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Dimension Color Size Measure Opacity Shape Labels...";
fil["74"]= "data_analysis/chart_types/plot_bubblechart_color.html@@@Chart Type: Color Encoded Bubble Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Color Dimension Size Measure Opacity Shape Labels...";
fil["75"]= "data_analysis/chart_types/plot_scatterplot.html@@@Chart Type: Scatter Plot@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Dimension Color Size Opacity Shape Labels...";
fil["76"]= "data_analysis/chart_types/plot_scatterplot_color.html@@@Chart Type: Color Encoded Scatter Plot@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Color Dimension Size Opacity Shape Labels...";
fil["77"]= "data_analysis/chart_types/plot_scatterplot_gradient.html@@@Chart Type: Gradient Grouped Scatter Plot@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Dimension Color Measure Size Opacity Shape Labels...";
fil["78"]= "data_analysis/chart_types/plot_scatterplot_shape.html@@@Chart Type: Shape Encoded Scatter Plot@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Measure Y-axis Measure Details Color Size Opacity Shape Dimension Labels...";
fil["79"]= "data_analysis/chart_types/time_line_chart.html@@@Chart Type: Line Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Date (Time-Series) Y-axis Measure Details Color Size Opacity Shape Labels...";
fil["80"]= "data_analysis/chart_types/time_line_chart_multiseries.html@@@Chart Type: Multi-Series Line Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Date (Time-Series) Y-axis Measure Details Dimension Color Size Opacity Shape Labels...";
fil["81"]= "data_analysis/chart_types/time_line_chart_multiseries_color.html@@@Chart Type: Color Encoded Multi-Series Line Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Date (Time-Series) Y-axis Measure Details Color Dimension Size Opacity Shape Labels...";
fil["82"]= "data_analysis/chart_types/time_line_chart_variable_color.html@@@Chart Type: Variable Color Line Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Date (Time-Series) Y-axis Measure Details Color Measure Size Opacity Shape Labels...";
fil["83"]= "data_analysis/chart_types/time_line_chart_variable_thickness.html@@@Chart Type: Variable Thickness Line Chart@@@Table 1. Chart Type Recipe Drop Zone Field Type X-axis Date (Time-Series) Y-axis Measure Details Color Size Measure Opacity Shape Labels...";
fil["84"]= "data_analysis/chart_types/viz_chart_gallery.html@@@Visualization Chart Types@@@You can create dozens of different types of charts depending on the types of fields placed in the viz drop zones. This sections gives samples of different chart types including the types of fields required in the different drop zones (chart type recipe). If the default mark type doesn t create the desired chart type, change the mark type from the Mark Type menu...";
fil["85"]= "data_analysis/computed_fields/add_vb_computed_field.html@@@Add a Vizboard Computed Field@@@You add a computed field by writing an expression that transforms existing fields. Computed fields help you refine your data analysis...";
fil["86"]= "data_analysis/computed_fields/vb_computed_fields_top.html@@@Differences between Dataset and Vizboard Computed Fields@@@You can add computed fields in a dataset or in the vizboard. While computed fields are largely the same in both interfaces, there are differences you need to be aware of...";
fil["87"]= "data_analysis/drill_down/dp_about_drill_down.html@@@About Drilling Down@@@When a lens has a dataset with a drill path defined in it, you can view measure data in more detail by navigating (drilling down) through the hierarchy of fields defined in the drill path. Drilling down in a viz allows analysts to easily explore the data and view it more granularly...";
fil["88"]= "data_analysis/drill_down/dp_drill_down.html@@@Drill Down Through Dimension Fields@@@Platfora provides access to all of your data, allowing analysts to interactively explore the data. Using Platfora’s drill down capability, analysts can more easily explore data in more detail by double-clicking on a dimension field in a visualization...";
fil["89"]= "data_analysis/drill_down/dp_drill_down_faq.html@@@Drill Down FAQ@@@This topic answers some frequently asked questions about drilling down in a Platfora visualization...";
fil["90"]= "data_analysis/drill_down/dp_drill_down_viz_chart_axis.html@@@Drill Down on a Field Value in a Chart Axis@@@Double-clicking on a field value for a drillable field on the axis of a Chart visualization drills down on that value...";
fil["91"]= "data_analysis/drill_down/dp_drill_down_viz_chart_mark.html@@@Drill Down on a Viz Mark@@@Double clicking on a single mark in a Chart visualization drills down on all drillable fields in the Builder panel...";
fil["92"]= "data_analysis/drill_down/dp_drill_down_viz_crosstab_cell.html@@@Drill Down on a Cross-Tab Cell@@@Double clicking on a single cell in a Cross-Tab visualization drills down on all drillable fields in the Builder panel...";
fil["93"]= "data_analysis/drill_down/dp_drill_up.html@@@Drill Up@@@When you drill down on a field, filters are created on that visualization. You can  drill up  in a viz by removing these filters...";
fil["94"]= "data_analysis/drill_down/dp_view_drill_path.html@@@View a Drill Path in a Viz@@@When a drillable field is in a drop zone, you can view all fields in each drill path the field is a member of. The current field is highlighted in bold to easily where in the path it’s located...";
fil["95"]= "data_analysis/funnel_analysis/analyze_funnel_viz.html@@@Analyze Funnel Viz@@@Funnel visualizations show the total number of users who reach each stage. You can also analyze funnels by comparing funnels across dimension fields...";
fil["96"]= "data_analysis/funnel_analysis/create_funnels.html@@@Create Funnel@@@To create a funnel analysis visualization, you first choose an event series lens and then define the stages in the funnel...";
fil["97"]= "data_analysis/funnel_analysis/define_funnel_stage.html@@@Define Funnel Stage@@@Define funnel stages in the stage builder of a viz of the funnel analysis viz type...";
fil["98"]= "data_analysis/funnel_analysis/funnel_viz_faq.html@@@Funnel Analysis Viz FAQs@@@A funnel is a visualization analysis type that tracks users  behavior across a sequence of events. This topic answers some frequently asked questions about funnel analysis visualizations...";
fil["99"]= "data_analysis/funnel_analysis/funnel_viz_top.html@@@Build Funnel Analysis Visualizations@@@Funnel analysis visualizations allow you to track user behavior across one or more fact datasets defined in an event series lens. The analysis is performed on individual events instead of aggregated data in order to find sequential patterns in behavior...";
fil["100"]= "data_analysis/funnel_analysis/funnel_viz_workspace.html@@@About the Funnel Analysis Viz Workspace@@@When you create and edit a funnel analysis visualization, the builder panels contain tools specifically needed to build a funnel viz. Use the panels on the left-hand side to select an event series lens, define the funnel stages, and analyze the funnels for different users. The panels on the right-hand side of the viz workspace show the data filters and comments applied to the selected viz...";
fil["101"]= "data_analysis/segments/choose_segment.html@@@Add a Segment to a Vizboard Lens as a Field@@@Segments can be added as a field to a lens in a vizboard that uses a dataset containing a defined segment. The available segments are listed. If the Select Segment menu is unavailable, no segment is available for the lens. When you add a segment field to a lens, it is added and made available to every viz in the vizboard that uses the same lens...";
fil["102"]= "data_analysis/segments/create_segment_from_chart_viz_lens.html@@@Create Segment from Chart Viz Lens@@@You can define a segment from scratch in any viz that uses a dataset referenced by another dataset...";
fil["103"]= "data_analysis/segments/create_segment_from_chart_viz_mark.html@@@Create Segment from Mark Selection@@@Segments can be created from a single selected mark in a viz. Platfora configures the segment attributes for you. You can accept the attributes as is, or modify them further...";
fil["104"]= "data_analysis/segments/create_segment_from_funnel_stage.html@@@Create Segment from Funnel Stage@@@Segments can be created from a selected stage in a funnel viz. Platfora configures the segment attributes for you, and they cannot be edited. When creating a segment from a stage, choose whether to include records that meet the stage criteria, or records that meet the previous stage criteria, but not the current stage s criteria (the records that dropped out at the current stage...";
fil["105"]= "data_analysis/segments/create_segment_top.html@@@Create Segments@@@Create segments from a viz that uses a dataset referenced by another dataset. The lens used in the viz can be created from the focus of either the fact or dimension dataset...";
fil["106"]= "data_analysis/segments/delete_segment.html@@@Delete a Segment@@@Deleting a segment from a dataset removes the segment definition and its data from the Platfora catalog...";
fil["107"]= "data_analysis/segments/remove_segment.html@@@Remove a Segment from a Vizboard Lens@@@Removing a segment from a vizboard lens makes it unavailable for analysis. The segment definition and data remain in the Platfora catalog...";
fil["108"]= "data_analysis/segments/segments_faq.html@@@Segments FAQs@@@A segment is a collection of users grouped together based on common behaviors and attributes. This topic answers some frequently asked questions about segments...";
fil["109"]= "data_analysis/segments/segments_top.html@@@Segments@@@Users can be grouped together so you can analyze events while looking for patterns among the group. Identify users that share similar behaviors by creating a segment, which is a collection of users grouped together based on common behaviors and attributes...";
fil["110"]= "data_analysis/segments/use_segment.html@@@Use Segments in a Viz@@@To use a segment as a field in a viz, the lens must contain a dimension (referenced) dataset that has a segment defined in it. The segment can be created in the current vizboard, a different vizboard using the same lens, or a different vizboard using a different lens with a common dimension dataset. When the segment was created in a different vizboard, you must first add it as a possible field in the current vizboard lens...";
fil["111"]= "data_analysis/sharing/about_data_lineage.html@@@What Data Lineage Includes@@@Data lineage includes more than a field s parent objects, it includes details about filters and expressions from those objects as well...";
fil["112"]= "data_analysis/sharing/data_lineage_configuring.html@@@Configuring Data Lineage Properties@@@Users with the System Administrator role can data lineage levels...";
fil["113"]= "data_analysis/sharing/data_lineage_levels.html@@@Interpret Data Lineage Levels@@@System administrators can configure how much of a data lineage to report...";
fil["114"]= "data_analysis/sharing/data_lineage_top.html@@@Tracing the Data Lineage of Viz Fields@@@Analysts can trace data lineage through Platfora lenses, datasets, all field types (computed, base, and measure), and data sources to the source files in Hadoop...";
fil["115"]= "data_analysis/sharing/export_viz_csv.html@@@Export Viz Data@@@You can export the data comprising a visualization as a CSV-formatted file, and download it to your local computer or to a remote file system such as HDFS or S3...";
fil["116"]= "data_analysis/sharing/export_viz_image.html@@@Export a Viz Image File@@@You can export a visualization as a PNG image file, and download it to your local computer...";
fil["117"]= "data_analysis/sharing/export_viz_image_email.html@@@Share a Viz Image File via Email@@@You can share a visualization with other users outside of Platfora by sending it in an email. The viz will be sent as a PNG image embedded in an email message. To share a viz via email, Platfora must be configured to connect to an email server...";
fil["118"]= "data_analysis/sharing/export_viz_lineage.html@@@Export Viz Data Lineage@@@Exporting data lineage to a JSON file for all fields in a visualization allows data analysts to see where the data in the fields ultimately came from and how they were manipulated in the process. The data lineage report includes filters applied to fields used in the viz...";
fil["119"]= "data_analysis/sharing/export_viz_top.html@@@Export Viz Data or Images@@@A visualization may have an interesting insight that you want to capture and/or share with others outside of Platfora. You may also want to use the results of a viz query for further data processing or exploration within Platfora. Platfora allows you to export viz images and dat...";
fil["120"]= "data_analysis/sharing/save_derived_dataset.html@@@Export a Viz as a New Dataset@@@You can choose to save the data comprising a visualization as a new dataset. This is called a derived dataset in Platfora. A derived dataset allows you to save the query results from a lens as a new dataset in the Platfora Data Catalog. Once a derived dataset is saved, you can use it as you would any other dataset in Platfora - you can edit it, add additional computed fields, and join it by reference to other datasets in the Platfora data catalog...";
fil["121"]= "data_analysis/sharing/share_PDF_rendering.html@@@How Platfora Renders a Vizboard as a PDF@@@This section lists the guidelines Platfora follows when rendering vizboards as PDF files...";
fil["122"]= "data_analysis/sharing/share_PDF_vizboard.html@@@Export Vizboard as a PDF@@@You can export a vizboard as a PDF file. You might want to do this to share insights discovered in Platfora with a larger group of people...";
fil["123"]= "data_analysis/sharing/share_vizboard_access.html@@@Grant Access to a Vizboard@@@The user that creates a vizboard is the default vizboard Owner. The vizboard owner can view, edit, or delete the vizboard. Vizboard owners can also change the vizboard access permissions to grant or revoke access permissions for other Platfora users...";
fil["124"]= "data_analysis/sharing/share_vizboard_permalink.html@@@Share Links to a Vizboard@@@Platfora provides a direct, permanent link (a permalink) to a vizboard that you can give to other Platfora users. Copy the permalink provided in the vizboard and share it with others by pasting, such as in a vizboard comment or email...";
fil["125"]= "data_analysis/sharing/viz_share_top.html@@@Save and Share Insights@@@As you prepare visualizations and vizboards, you can share your insights with other Platfora users, collaborate with other analysts on your findings, or export the viz or underlying data for use in an outside presentation or application...";
fil["126"]= "data_analysis/supplement/derive_new_lens_from_viz.html@@@Create a New Lens From Viz@@@You can create a new lens from a visualization as well as from the data catalog. The newly created lens uses the same datasets as the viz s lens, and it includes the fields used in the viz by default. However, you can add or remove fields from the new lens before saving it...";
fil["127"]= "data_analysis/supplement/request_more_lens_data.html@@@Request Additional Lens Data@@@When working in a viz, sometimes the lens used in the viz doesn t contain all data you need. If you have the appropriate permissions, you can add new dataset fields to the current lens or create a new lens from the current dataset and include additional fields...";
fil["128"]= "data_analysis/supplement/supplement_lens_data_top.html@@@Enhance and Supplement Lens Data in a Viz@@@The data available for a viz is determined by the fields made available in the lens. If the lens currently doesn t have the data you need, you can modify the lens to add more fields if you have the proper permissions. Data analysts without the permissions to edit a lens still have other options to enhance and supplement existing lens dat...";
fil["129"]= "data_analysis/vizboards/viz_layout_top.html@@@Manage Viz Layout@@@Vizboard pages can contain one or more visualizations. You can arrange visualizations on a page and edit, rename, and delete them as necessary...";
fil["130"]= "data_analysis/vizboards/vizboard_add_new.html@@@Add a New Vizboard@@@You can create a new, empty vizboard by clicking the Add Vizboard button from the Vizboards page. Each new vizboard contains one page with one empty visualization to help you get started...";
fil["131"]= "data_analysis/vizboards/vizboard_add_page.html@@@Add a Vizboard Page@@@By default, a new vizboard has one page. You can add additional pages to the vizboard, navigate between pages, and move visualizations between pages using the Pages tool panel...";
fil["132"]= "data_analysis/vizboards/vizboard_arrange_page_layout.html@@@Arrange Visualizations on a Vizboard Page@@@By default, new visualizations are added to the middle of a vizboard page in fixed-size panel. You can move and resize visualizations on a vizboard page by dragging them by the panel borders...";
fil["133"]= "data_analysis/vizboards/vizboard_close.html@@@Close a Vizboard@@@To close a vizboard, just navigate off the page by clicking any other page in the top navigation header. Make sure to Save the vizboard before you exit if you do not want to lose your work...";
fil["134"]= "data_analysis/vizboards/vizboard_duplicate.html@@@Duplicate a Vizboard@@@Save As makes a copy of the current vizboard and saves it as a new vizboard. Note that the underlying lens data is not saved when you duplicate a vizboard, only the page and visualization definitions. Any unsaved changes in the current vizboard will be saved in the duplicate copy, but not in the original vizboard. The version history in the Restore menu is not carried forward to the new vizboard...";
fil["135"]= "data_analysis/vizboards/vizboard_edit_viz.html@@@Edit a Visualization@@@To edit a visualization in a vizboard, simply click anywhere inside the visualization. Use the tools in the Builder panels to work on the visualization...";
fil["136"]= "data_analysis/vizboards/vizboard_hide_panels.html@@@Show and Hide Tool Panels@@@You can show and hide the Pages, Builder, and Filters tool panels as you work on a vizboard page. Hiding the panels allows you to have more workspace for viewing and arranging visualizations. When you need to edit a visualization or page, you can toggle the tool panels on again...";
fil["137"]= "data_analysis/vizboards/vizboard_layout_top.html@@@Arranging Vizboard Pages@@@A vizboard is made up of one or more pages. A page can contain multiple visualizations, and those visualizations may or may not use the same underlying lens data. Within a page, you can add multiple visualizations, edit them, arrange them, or delete them. While working in a vizboard, you work on one page at a time, but you can easily move visualizations between pages...";
fil["138"]= "data_analysis/vizboards/vizboard_live_updates.html@@@Turn Live Updates Off and On@@@When working in a vizboard, you can choose to pause live updates for the vizboard. This allows you to conserve resources on the Platfora cluster by reducing the number of times the web application queries and renders dat...";
fil["139"]= "data_analysis/vizboards/vizboard_manage_history.html@@@Manage Vizboard Versions@@@The Restore menu has a history of each time a vizboard was saved, ordered from most recent to oldest. Versions are named by the date and time they were created, along with the name of the user who saved the version. You cannot rename versions. You can only delete or restore versions...";
fil["140"]= "data_analysis/vizboards/vizboard_rename.html@@@Rename a Vizboard@@@You can change the name of a vizboard at any time by opening it and changing its name from the vizboard title bar. All vizboards are given a default name of Untitled Vizboard when they are first created. You must have edit permissions on a vizboard in order to rename it...";
fil["141"]= "data_analysis/vizboards/vizboard_resize_page.html@@@Resize a Page to Fit the Browser Window@@@While working in a vizboard, you can resize the visualizations to fit the available canvas area on the page. This allows you to easily adjust the page canvas size as you resize your browser window or show and hide the Builder panels...";
fil["142"]= "data_analysis/vizboards/vizboard_revert.html@@@Restore a Vizboard to a Previous Version@@@Restoring a vizboard to a previous version allows you to rollback the vizboard to a previously saved state, then continue working from that point. If you want to keep the current state of the vizboard as well, be sure to Save before restoring. Any unsaved changes will be discarded when you restore to a previous version...";
fil["143"]= "data_analysis/vizboards/vizboard_save_preview.html@@@Save and Preview a Vizboard@@@Save and Preview allows you to save a vizboard and preview it in presentation mode. This allows you to view and test the vizboard as view-only users will see it if you publish or share it. While in preview mode, the viz builder tools and vizboard edit controls are hidden...";
fil["144"]= "data_analysis/vizboards/vizboard_save_top.html@@@Save a Vizboard@@@It is best practice to save your work each time you add or change a visualization or page in a vizboard. Vizboards are not auto-saved as you work. If you leave or reload the vizboard without saving your changes first, or if the browser closes unexpectedly, any unsaved changes will be lost...";
fil["145"]= "data_analysis/vizboards/vizboard_undo_redo.html@@@Using Undo and Redo in a Vizboard@@@While working in an ad hoc analysis vizboard, you can undo and redo your changes to pages and visualizations. A history of actions is kept for the current session only. Leaving the vizboard page clears the action history...";
fil["146"]= "data_analysis/vizboards/vizboard_workspace.html@@@The Vizboard Workspace@@@The vizboard is where you create and manage visualizations around a particular business question, project, or subject area. A vizboard contains pages, and pages contain visualizations...";
fil["147"]= "data_analysis/vizboards/vizboards_top.html@@@Working in a Vizboard@@@In Platfora, the vizboard is where you create and manage visualizations around a particular project or subject area. Typically, you would create one vizboard for each data analysis project that you are working on. A vizboard can contain one or more pages and pages can contain one or more visualizations...";
fil["148"]= "data_catalog/browse_datasets.html@@@Find Available Datasets@@@Datasets represent a collection of source data in Hadoop that has been modeled for use in Platfora. You can browse or search the data catalog to find datasets that are available to you and that meet your data requirements. Once you find a dataset of interest, you can request that data by building a lens (or check if a lens already exists that has the data you need...";
fil["149"]= "data_catalog/browse_lenses.html@@@Find Available Lenses@@@Lenses contain data that is already loaded into Platfora and immediately available for analysis. Lenses are always built from the focus of a single dataset in the data catalog. Before you build a new lens, you should check if there is already a lens that has the data you need. You can browse the available lenses in the Platfora data catalog...";
fil["150"]= "data_catalog/browse_segments.html@@@Find Available Segments@@@The data catalog does not have a centralized tab or view that shows all of the segments that have been created in Platfora. You can find segments by looking in a particular dataset to see if any segments have been created from that dataset...";
fil["151"]= "data_catalog/data_catalog.html@@@Explore the Data Catalog@@@The data catalog is a collection of data items available and visible to Platfora users. Data administrators build the data catalog by defining and modeling datasets in Platfora that point to source data in Hadoop. When users request data from a dataset, that request is materialized in Platfora as a lens. The data catalog shows all of the datasets (data available for request) and lenses (data that is ready for analysis) that have been created by Platfora users...";
fil["152"]= "data_catalog/data_catalog_faq.html@@@Data Catalog FAQ@@@The data catalog is where users can find datasets, lenses, and segments that have been created in Platfora. This topic answers some frequently asked questions about the data catalog...";
fil["153"]= "data_catalog/label_objects.html@@@Organize Datasets, Lenses and Vizboards with Labels@@@If you have datasets, lenses, and vizboards that you use all of the time, you can tag them with a label so you can easily find them. Labels allow you to organize and categorize Platfora objects for easier search and collaboration. For example, you can label all datasets, lenses and vizboards associated with a particular department or project...";
fil["154"]= "data_source/about_uploads_datasource.html@@@About the Uploads Data Source@@@When you first start the Platfora server, it connects to the configured distributed file system (DFS) for Hadoop, and creates a default data source named Uploads. This data source cannot be deleted. You can upload single files residing on your local file system, and they will be copied to the Uploads data source in Hadoop...";
fil["155"]= "data_source/about_uploads_security.html@@@About Security on Uploaded Files@@@By default, data access permissions on the Uploads data source is granted to the Everyone group. Object permissions allow the Everyone group to define datasets from the data source (and thereby upload files to this data source...";
fil["156"]= "data_source/add_datasource.html@@@Add a New Data Source@@@A data source is a connection to a mount point or directory on an external data server, such as a file system or database server. Platfora currently provides data source adapters for Hive﻿, HDFS, Amazon S3, and MapR FS...";
fil["157"]= "data_source/add_hdfs_datasource.html@@@Connect to an HDFS Data Source@@@Creating an HDFS data source involves specifying the connection information to the HDFS NameNode server. Once you have successfully connected, you will be able to browse the files and directories in HDFS, and choose the files that you want to add to Platfora as datasets...";
fil["158"]= "data_source/add_hive_datasource.html@@@Connect to a Hive Data Source@@@When Platfora uses Hive as a data source, it connects to the Hive metastore to query information about the source data. There are multiple ways to configure the Hive metastore service in your Hadoop environment. If you are using the Hive Thrift Metastore (known as the remote metastore client configuration), you can add a Hive data source directly in the Platfora application...";
fil["159"]= "data_source/add_hive_datasource_rdbms.html@@@Connecting to a Hive RDBMS Metastore@@@If you are not using the Hive Thrift Metastore server in your Hadoop environment, you can configure Platfora to connect directly to a Hive metastore relational database management system (RDBMS), such as MySQL. This requires additional configuration on the Platfora master server that must be done before you can create the data source in the Platfora application...";
fil["160"]= "data_source/add_hive_datasource_thrift.html@@@Connecting to a Hive Thrift Metastore@@@By default, the Platfora application allows you to connect the the Hive Thrift Metastore service. To use the Thrift server as a data source for Platfora, you must start the Hive Thrift Metastore server in your Hadoop environment and know the URI to connect to this server...";
fil["161"]= "data_source/add_mapr_datasource.html@@@Connect to a MapR Data Source@@@Creating a MapR data source involves specifying the connection information to the MapR Container Location Database (CLDB) server. Once you have successfully connected, you will be able to browse the files and directories in the MapR file system, and choose the files that you want to add to Platfora as datasets...";
fil["162"]= "data_source/add_other_datasource.html@@@Connect to Other Data Sources@@@The Other data source type allows you to specify a connection URL to an external data source server. You can use this to create a data source when you already know the protocol and URL to connect to a supported data source type...";
fil["163"]= "data_source/add_s3_datasource.html@@@Connect to an S3 Data Source@@@Amazon Simple Storage Service (Amazon S3) is a distributed file system hosted on Amazon Web Services (AWS). Data transfer is free between S3 and Amazon cloud servers, making S3 an attractive choice for users who run their Hadoop clusters on EC2 or utilize the Amazon EMR service...";
fil["164"]= "data_source/add_upload_datasource.html@@@Upload a Local File@@@You can upload a file through the Platfora application and it will be copied to the default Uploads data source in Hadoop. Once a file is uploaded, you can then select it as the basis for a dataset...";
fil["165"]= "data_source/config_datasource_security.html@@@Configure Data Source Security@@@Only system administrators can create data sources in Platfora. Access to the files in a data source location is controlled by granting data access permissions to the data source. The ability to manage or define datasets from a data source is controlled by its object permissions...";
fil["166"]= "data_source/datasources.html@@@Connect to Data Sources@@@The first step in making Hadoop data available in Platfora is identifying what source data you want to expose to your business users, and making sure the data is in a format that Platfora can work with. Although the source data may be coming into Hadoop from a variety of source systems, and in a variety of different file formats, Platfora needs to be able to parse it into rows and columns in order to create a dataset in Platfora. Platfora supports a number of data sources and source file formats...";
fil["167"]= "data_source/delete_datasource.html@@@Delete a Data Source@@@Deleting a data source from Platfora removes the data source connection as well as any Platfora dataset definitions you have created from that data source. It does not remove source files or directories from the source file system, only the Platfora definitions. The default Uploads data source cannot be deleted...";
fil["168"]= "data_source/edit_datasource.html@@@Edit a Data Source@@@You typically do not need to edit a data source once you have successfully established a connection. If the connection information changes, however, you can edit an existing data source to update its connection information, such as the server name or port of the data source. You cannot, however, change the name of a data source after it has been created...";
fil["169"]= "data_source/supported_source_types.html@@@Supported Data Sources@@@Hadoop supports many different distributed file systems, of which HDFS is the primary implementation. Platfora provides data adapters for a subset of the file systems that Hadoop supports. Hadoop also has various database and data warehouse implementations, some of which can be used as data sources for Platfora. This section describes the data sources supported by Platfor...";
fil["170"]= "dataset/about_dataset_workspace.html@@@About the Dataset Workspace@@@When you add new dataset or edit an existing one, you are brought to the dataset workspace. This is where you describe the structure and characteristics of your source data in the form of a Platfora dataset...";
fil["171"]= "dataset/add_new_dataset.html@@@Add a New Dataset@@@In order to add a new dataset to Platfora, the source data files on which the dataset is based must be in the Hadoop file system and accessible to the Platfora application. Platfora takes a sampling of records from a source file and guides you through a series of steps to define the structure and processing rules for the dat...";
fil["172"]= "dataset/common_lang_elements_top.html@@@Understand Expression Basics@@@In this section you learn how Platfora s expression language and programmatic query support are related, where you can use them, and which components they share...";
fil["173"]= "dataset/config_dataset_security.html@@@Configure Dataset Security@@@Only system administrators or data administrators (with the appropriate data source permissions) can create datasets. The ability to manage or define lenses from a dataset is controlled by the dataset object permissions...";
fil["174"]= "dataset/dataset_top.html@@@Define Datasets@@@Source data is mapped into Platfora by creating a dataset. A dataset describes the characteristics of the source data, such as its file locations, the structure of individual rows or records, the fields and data types, and the processing logic to cleanse, transform, and aggregate the data when it is loaded into Platfora. The collection of modeled datasets make up the data catalog (the source data items available to Platfora users...";
fil["175"]= "dataset/define_dataset_key.html@@@Define the Dataset Key@@@A key is single field (or combination of fields) that uniquely identifies a row in a dataset, similar to a primary key in a relational database. A dataset must have a key defined in order to be the target of a reference, the base dataset of a segment, or the focus of an event series lens. Also, the key field(s) used to join two datasets must be of the same data type...";
fil["176"]= "dataset/delete_dataset.html@@@Delete a Dataset@@@Deleting a dataset from Platfora removes the dataset definition from the Platfora data catalog...";
fil["177"]= "dataset/duplicate_dataset.html@@@Duplicate a Dataset@@@Platfora allows users to make a copy of an existing dataset. The duplicated dataset uses the same characteristics as the original dataset, such as its data source and field definitions...";
fil["178"]= "dataset/edit_dataset.html@@@Edit a Dataset@@@Defining a dataset is often an iterative process. You can edit a dataset definition at any time to modify its descriptions, source location, parsing logic, and processing rules. However, you cannot change the name of a dataset once it has been saved the first time...";
fil["179"]= "dataset/use_expressions_top.html@@@Work with Platfora s Expression Language@@@Platfora includes an expression language to support advanced data analysis processing...";
fil["180"]= "dataset/drill_paths/add_drill_path.html@@@Add a Drill Path@@@Drill paths are defined in a dataset. You can define drill paths when adding a new dataset or when editing an existing one...";
fil["181"]= "dataset/drill_paths/drill_path_faq.html@@@Drill Path FAQ@@@This topic answers some frequently asked questions about defining and using drill paths in Platfor...";
fil["182"]= "dataset/drill_paths/drill_paths_top.html@@@Drill Paths@@@Adding a drill path to a dataset allows vizboard users to drill down to more granular levels of detail in a viz. A drill path is defined in a dataset by specifying a hierarchy of dimension fields...";
fil["183"]= "dataset/manage_fields/about_dataset_fields.html@@@About Dataset Fields@@@A field is an atomic unit of data that has a name, a value, and a data type. Within a dataset, there are two basic classes of fields or columns: Base and Computed...";
fil["184"]= "dataset/manage_fields/about_field_visibility.html@@@About Field Visibility@@@A data administrator can control what fields of a dataset are visible to Platfora users. Hidden fields are not visible in the data catalog view of the dataset and connot be selected for a lens...";
fil["185"]= "dataset/manage_fields/about_null_handling.html@@@About Null and Default Values@@@If a record does not have a value for a particular field, the field is treated as a null (empty) value. When Platfora builds a lens, null values are substituted with the default field values defined in the dataset...";
fil["186"]= "dataset/manage_fields/manage_fields_top.html@@@Manage Dataset Fields@@@The Manage Fields step of the dataset workspace is where you verify, cleanse, and transform the raw data fields into the actual fields that users can browse and select in the Platfora data catalog. This is where the majority of the dataset definition work is performed...";
fil["187"]= "dataset/manage_fields/supported_data_types.html@@@About Platfora Data Types@@@Platfora has a number of built-in data types you can assign to dataset fields...";
fil["188"]= "dataset/manage_fields/use_computed_top.html@@@Use Computed Fields@@@You can add computed fields in a dataset or in the vizboard. This section discusses some differences between computed fields in datasets and vizboards, provides examples of computed fields, and discusses troubleshooting errors...";
fil["189"]= "dataset/manage_fields/base/add_field_descriptions.html@@@Add Field Descriptions@@@Field descriptions are displayed in the data catalog view of a dataset or lens, and can help users decide if a field is relevant for their needs. Data administrators should add helpful field descriptions that explain the meaning and data value characteristics of a field...";
fil["190"]= "dataset/manage_fields/base/bulk_edit_dataset_fields.html@@@Edit Multiple Fields at Once@@@When a dataset has a lot of fields to manage, it may be easier to update several field names, data types, descriptions, and visibility settings all at once rather than editing each field one-by-one in the Platfora application. To do this, you can upload a comma or tab delimited text file containing the field information you want to set...";
fil["191"]= "dataset/manage_fields/base/casting_to_datetime.html@@@Set DATETIME Data Types@@@If Platfora can recognize the format of a date field, it will automatically cast it to the DATETIME data type. However, some date formats are not automatically recognized by Platfora and need to be converted to DATETIME using a computed field expression...";
fil["192"]= "dataset/manage_fields/base/change_field_names.html@@@Rename Dataset Fields@@@The field name defined in the dataset is what users see when they browse the Platfora data catalog. In some cases, the field names imported from the source data may be fine. In other cases, you may want to change the field names to something more understandable for your users...";
fil["193"]= "dataset/manage_fields/base/confirm_datatypes.html@@@Set Base Field Data Types@@@The dataset parser will guess the data type of a field based on the sampled source data, but you may need to change the data type depending on the additional processing you plan to do...";
fil["194"]= "dataset/manage_fields/base/hide_dataset_fields.html@@@Hide Dataset Columns (Fields)@@@Hiding a column or field in a dataset definition removes it from the data catalog view of the dataset. Users cannot see hidden columns when browsing datasets in the data catalog, or select them when they build a lens...";
fil["195"]= "dataset/manage_fields/base/manage_base_fields.html@@@Manage Base Fields@@@When you first add a dataset, it only has its Base fields. These are the fields parsed direcly from the raw source dat...";
fil["196"]= "dataset/manage_fields/computed/about_binned_fields.html@@@About Binned Fields@@@A binned field is a special kind of computed field that groups ranges of values together to create new categories...";
fil["197"]= "dataset/manage_fields/computed/about_expression_functions.html@@@Functions in an Expression@@@Functions perform common data processing tasks. While not all expressions contain functions, most do. This section describes basic concepts you need to know to use functions...";
fil["198"]= "dataset/manage_fields/computed/about_expression_operators.html@@@Operators in an Expression@@@Platfora has a number of built-in operators for doing arithmetic, logical, and comparison operations...";
fil["199"]= "dataset/manage_fields/computed/add_binned_field.html@@@Bin Numeric Values@@@You can bin numeric values by adding a binned quick field...";
fil["200"]= "dataset/manage_fields/computed/add_bucket_field.html@@@Bin Text Values@@@If you wanted to bin text or STRING values, you can define a computed field that groups values together using a CASE expression...";
fil["201"]= "dataset/manage_fields/computed/add_computed_field.html@@@Add a Computed Field@@@You add a computed field by writing an expression that transforms existing fields. Computed fields help you refine your data processing...";
fil["202"]= "dataset/manage_fields/computed/computed_field_examples.html@@@Computed Field Examples@@@This section contains examples of some common data processing tasks you can accomplish using Platfora computed fields...";
fil["203"]= "dataset/manage_fields/computed/fields_in_expressions.html@@@Fields in an Expression@@@This section explains how to use field names in expressions...";
fil["204"]= "dataset/manage_fields/computed/literals_in_expressions.html@@@Literal Values in an Expression@@@This section explains how to use literals in expressions...";
fil["205"]= "dataset/manage_fields/computed/manage_computed_fields.html@@@Manage Computed Fields@@@A source dataset contains a number of base fields parsed directly from the source data. You can add additional computed fields to do basic data cleansing and transformation tasks (such as transforming values to something more meaningful for your users), or to derive values from other fields (such as computing an age from a birth date...";
fil["206"]= "dataset/manage_fields/computed/troubleshooting_expressions.html@@@Troubleshoot Computed Field Errors@@@When you create a computed field Platfora catches any syntax error in your expression when you try to save the field. This section describes the most common causes of expression syntax errors...";
fil["207"]= "dataset/manage_fields/event_series/esp_expression_language.html@@@Understand the PARTITION Expression Language@@@Event patterns are typically sequential. For this reason, sorting the records by time usually allows you to discover unique sequences, patterns, or event paths that occur in your dat...";
fil["208"]= "dataset/manage_fields/event_series/esp_fields_top.html@@@Event Series Processing Computed Fields@@@You can add an event series processing computed field to a Platfora dataset. Event series processing is also referred to as pattern matching or event correlation...";
fil["209"]= "dataset/manage_fields/event_series/esp_processing_order.html@@@Understand Pattern Match Processing Order@@@During lens processing, the build evaluates patterns row-by-row from the partitions top row and going downwards. A pattern match is evaluated based on the current row, and any rows that come before (in terms of their position in the partition). The pattern match only looks back from the current row – it does not look ahead to the next row in the partition...";
fil["210"]= "dataset/manage_fields/event_series/esp_processing_precedence.html@@@About Pattern Match Precedence@@@By default, pattern expressions are matched from left to right. The innermost parenthetical expressions are evaluated first and then moving outward from there...";
fil["211"]= "dataset/manage_fields/event_series/esp_processing_steps.html@@@How Event Series Processing Works@@@This section explains how even series processing works by walking you through a simple use of the PARTITION() function...";
fil["212"]= "dataset/manage_fields/event_series/esp_regex_quantifiers.html@@@About Regex-Style Quantifiers (Greedy and Reluctant)@@@The PATTERN clause can use regex-style quantifiers to denote the frequency of a match...";
fil["213"]= "dataset/manage_fields/event_series/esp_tips.html@@@Event Series Processing Tips@@@Event series processing computed fields, unlike other computed fields, require advanced processing during lens builds. This means they require more compute resources on your Hadoop cluster. This section discusses what to consider when adding event series computed fields to your dataset definitions...";
fil["214"]= "dataset/manage_fields/measures/add_complex_measure.html@@@Add Computed Measures@@@In addition to quick measures, you can create more sophisticated measures using expressions.You use computed field containing an aggregate function to create a measure...";
fil["215"]= "dataset/manage_fields/measures/add_simple_measure.html@@@Add Quick Measures@@@If you have a field in your dataset that you want to use for quantitative analysis, you can select that field and quickly add measures to the dataset. A quick measure sets the default aggregation(s) to use when a user builds a lens...";
fil["216"]= "dataset/manage_fields/measures/default_count_measure.html@@@The Default  Total Records  Measure@@@Platfora automatically adds a default measure to every dataset you create. This measure is called Total Records, and it counts the number of records (or rows) in the dataset. You can change the name, description, or visibility of this default measure, but you cannot delete it. When you build a lens from a dataset, this measure is always selected by default...";
fil["217"]= "dataset/manage_fields/measures/manage_measure_fields.html@@@About Measures@@@To define a dataset you must determine which fields to use as measures. Then, you define how to aggregate those fields. You do this by either defining a new computed field or by adding quick measures on an existing field...";
fil["218"]= "dataset/manage_fields/measures/rollup_measures.html@@@Use ROLLUP Measures with Aggregate Functions@@@ROLLUP functions modify aggregate functions and allow you to calculate complex measures. Using a ROLLUP you can build windowed, partitioned, or adaptive frames around your data. This section describes the different types of measures you can create with a ROLLUP modifier...";
fil["219"]= "dataset/parse/hive_datatype_mapping.html@@@Hive to Platfora Data Type Mapping@@@When you create a dataset based on a Hive table, Platfora maps the data types of the Hive columns to one of the Platfora internal data types...";
fil["220"]= "dataset/parse/hive_partitioning.html@@@How Platfora Uses Hive Partitions and Buckets@@@Hive source tables can be partitioned, bucketed, neither, or both. In Platfora, datasets defined from Hive table sources take advantage of the partitioning defined in Hive. However, Platfora does not exploit the clustering or sorting of bucketed tables at this time...";
fil["221"]= "dataset/parse/hive_serde.html@@@Enable Hive SerDes in Platfora@@@If you are using Hive as a data source, Platfora must be able to parse the underlying source data files that a Hive table definition refers to. For Hive to be able to support custom file formats, you implement Serialization/Deserialization (SerDe) libraries in Hive that describe how to read (or parse) and write the data. Any custom SerDe libraries that you implement in Hive must also be installed in Platfor...";
fil["222"]= "dataset/parse/parse_add_custom_delimiter.html@@@Add a Custom Delimiter@@@In some cases, your source data may use a custom delimiter that is not available in the Column Delimiter or Row Delimiter menu choices. Platfora allows you to define a custom delimiter as either a character string or as a decimal-encoded ASCII value...";
fil["223"]= "dataset/parse/parse_avro_data.html@@@Parse Avro Files@@@The Platfora Avro parser supports Avro container files where the top-level object is an Avro record data type. The file must have a JSON schema declared at the beginning of the file, and the serialized data must be in the Avro binary-encoded format...";
fil["224"]= "dataset/parse/parse_avro_datatype_map.html@@@Avro to Platfora Data Type Mapping@@@Avro has a set of primitive and complex data types it supports. These are mapped to Platfora s internal data types...";
fil["225"]= "dataset/parse/parse_data_top.html@@@Parse Source Data into Rows and Columns@@@The Parse Data step of the dataset workspace is where you describe your source data in tabular format by parsing it into rows (records) and columns (fields). For Platfora to be able to parse the source data, each record must have a similar data structure...";
fil["226"]= "dataset/parse/parse_delimited_data.html@@@Parse Delimited Files@@@A delimited file is a plain text file format for describing tabular data. It refers to any file that is plain text (typically ASCII or Unicode characters), has one record per line, has records divided into fields, and has the same sequence of fields for every record...";
fil["227"]= "dataset/parse/parse_hive_table.html@@@Parse Hive Tables@@@When creating a dataset from a Hive table, there is no need to define parsing controls in Platfora. Platfora uses the Hive table definition to obtain metadata about the source data, such as which files to process, the parsing logic for rows and columns, and the field names and data types contained in the source data. You can only create a dataset based on Hive tables, not Hive views...";
fil["228"]= "dataset/parse/parse_json_data.html@@@Parse JSON Files@@@The Platfora JSON parser supports the selection of a top-level JSON object to signify a record or row, and selection of name:value pairs within an object to signify columns or fields (including nested objects and arrays...";
fil["229"]= "dataset/parse/parse_json_supported_formats.html@@@Supported JSON File Formats@@@There are two general types of JSON files supported by Platfora: JSON Object per line files and top-level JSON Object files...";
fil["230"]= "dataset/parse/parse_line.html@@@Parse Raw Lines with Platfora Expressions@@@The Line parser simply returns each line in the source file as one column value, essentially not parsing the source data at all. This allows you to bypass the parsing step and instead define a series of computed fields to extract the desired column values out of each line...";
fil["231"]= "dataset/parse/parse_other.html@@@Parse Other File Types@@@For other file types that cannot be parsed using the built-in parsing controls, Platfora provides two generic parsers: Regex and Line. As long as your source data has one record per line, you can use one of these generic parsers to extract columns from semi-structured source dat...";
fil["232"]= "dataset/parse/parse_regex.html@@@Parse Raw Lines with a Regular Expression@@@The Regex parser allows you to search lines in the source data and extract columns using a regular expression...";
fil["233"]= "dataset/parse/parse_web_logs.html@@@Parse Web Access Logs@@@A web access log contains records about incoming requests made to a web server. Platfora has a built-in Web Access Log parser that automatically recognizes web access logs that adhere to the NCSA common or combined log formats...";
fil["234"]= "dataset/parse/parse_weblog_format.html@@@Supported Web Access Log Formats@@@Platfora supports web access logs that comply with the NCSA common or combined log formats. This is the log format used by many popular web servers (such as Apache HTTP Server...";
fil["235"]= "dataset/parse/parse_xml_data.html@@@Parse XML Files@@@The Platfora XML parser supports the selection of a top-level XML element to signify a record or row, and selection of attribute:value or element:value pairs to signify columns or fields (including those in nested elements...";
fil["236"]= "dataset/parse/parse_xml_supported_formats.html@@@Supported XML File Formats@@@There are two general types of XML files supported by Platfora: XML Element per line files and top-level XML Document files...";
fil["237"]= "dataset/parse/view_raw_data.html@@@View a Sampling of Source Data@@@Platfora shows a sample of records taken from a source data file so you can see the data in its original format...";
fil["238"]= "dataset/references/about_datetime_references.html@@@About Date and Time References@@@Slicing and dicing data by date is a very common reporting requirement. Platfora allows you to analyze date and time-based data at different granularities by automatically linking DATETIME fields to Platfora s built-in Date and Time dimension datasets...";
fil["239"]= "dataset/references/about_events.html@@@How Events Work in Platfora@@@An event is similar to a reference, but the direction of the join is reversed. An event joins the primary key field(s) of a dimension dataset to the corresponding foreign key field(s) in a fact dataset, plus designates a timestamp field for ordering the event records...";
fil["240"]= "dataset/references/about_references.html@@@How References Work in Platfora@@@Creating a reference allows the datasets to be joined when building lenses and executing queries, similar to a foreign key to primary key relationship in a relational database. References are typically created in a fact dataset, and point to a dimension dataset...";
fil["241"]= "dataset/references/add_event.html@@@Add an Event Reference@@@An event is a special reverse-reference that is created in a dimension dataset. Before you can model event references, you must define regular references first. Event references allow you to define an event series lens from a dataset...";
fil["242"]= "dataset/references/add_reference.html@@@Add a Reference@@@A reference creates a link from a field in the current dataset to the primary key field of another dataset. The focus dataset must have a primary key defined. Also, the fields used to join two datasets must be of the same data type...";
fil["243"]= "dataset/references/delete_event.html@@@Delete an Event Reference@@@Deleting an event removes the link from a dimension dataset to a fact dataset. Deleting an event disables the ability to build an event series lens that includes the event...";
fil["244"]= "dataset/references/delete_reference.html@@@Delete a Reference@@@Deleting a reference removes the link between two datasets. If you want to keep the reference link, but do not want the reference to appear in the data catalog, you can always hide it instead. The automatic references to Date and Time cannot be deleted, but they can be hidden...";
fil["245"]= "dataset/references/model_references_and_events.html@@@Model Dataset References and Events@@@A reference allows two datasets to be joined together on fields that they share in common. A reference creates a link in one dataset to the primary key of another dataset. An event is similar to a reference, except that the direction of the reference link is reversed. An event is created in a dataset that has a primary key and points to a foreign key field in another dataset...";
fil["246"]= "dataset/select_source/build_lzo_package.html@@@Create LZO Compression Package (Optional)@@@This optional procedure illustrates how to build a LZO for Hadoop. Following this procedure is only necessary if you want to build and install your own package...";
fil["247"]= "dataset/select_source/change_raw_sample_file.html@@@Change the Sample File for a Dataset@@@Platfora shows a sampling of 20 records taken from the first file in the source location by default. You can change the sampling file to see a different selection of sample records...";
fil["248"]= "dataset/select_source/edit_source_location.html@@@Change the Source File Location for a Dataset@@@From the Data Catalog page, open the dataset you want to edit. Click Edit Dataset to open the dataset workspace. Click Source Data in the dataset header. Edit the Source Location path to point to the...";
fil["249"]= "dataset/select_source/lzo_compression_libs.html@@@Configure LZO Compression for Platfora@@@This section describes how to support for LZO compressed files to Platfora. Hadoop expects splittable compression formats. For that reason, the LZO compressed file format requires both the base LZO installation and the Hadoop-LZO GitHub project...";
fil["250"]= "dataset/select_source/select_data_top.html@@@Select Source Data@@@After you have created a data source, the first step in creating a dataset is selecting some Hadoop source data to expose in Platfora. This is accomplished by choosing files from the source file system...";
fil["251"]= "dataset/select_source/select_dfs_directory.html@@@Select DFS Source Files@@@For distributed file system data sources, such as HDFS or S3, a data source points to a particular directory in the file system. From that point, you can browse and select the source files to include in your dataset. You can enter a wildcard pattern to select multiple files including files from multiple directory locations, however all of the files selected must be of the same file format...";
fil["252"]= "dataset/select_source/select_hive_table.html@@@Select a Hive Source Table@@@For Hive data sources, Platfora points to a Hive metastore server. From that point, you can browse the available databases and tables, and select a single Hive table on which to base your dataset. Since Hive tables are already in tabular format, the parsing step is skipped for Hive data sources. Platfora does not execute any queries through Hive; it only uses the table definition to obtain the metadata needed to define the dataset...";
fil["253"]= "dataset/select_source/supported_compression_libs.html@@@Configure Compression Formats@@@Compressed data can save storage space and improve data transfer speeds. Alternatively, CPU utilization and processing time can increase during decompression. Platfora includes support for several file compression formats. You can add support for others...";
fil["254"]= "dataset/select_source/supported_file_types.html@@@Supported Source File Formats@@@To ingest source data, Platfora uses its parsing facilities to parse the data into records (rows) and fields (columns). Source files that support compression can be compressed. Platfora supports the following file formats...";
fil["255"]= "dataset/select_source/thirdparty_compression_libs.html@@@Add Third-party Compression Format Support@@@If you want to use a third-party compression format that is not one of Platfora s officially supported formats, your system administrator must do some additional configuration to both Platfora and Hadoop...";
fil["256"]= "dataset/select_source/troubleshoot_compression_libs.html@@@Troubleshoot Compression Problems@@@This page explains how to resolve problems you may encounter ingesting compressed files into Platfor...";
fil["257"]= "export_data/export_lens_data.html@@@Export Lens Data@@@Platfora allows you to export lens data for use in other tools or applications. Lens data can be exported in comma-separated values (csv) format to a remote file system such as HDFS or Amazon S3...";
fil["258"]= "export_data/export_lens_data_faq.html@@@Data Export FAQ@@@Lens data exports allow you to copy data out of Platfora. This topic answers some frequently asked questions about lens data exports...";
fil["259"]= "export_data/export_lens_to_remote_fs.html@@@Export a Lens as CSV@@@Exporting a lens writes out the data in parallel to a distributed file system such as HDFS or S3. You can export an entire lens from the Platfora data catalog. You can export a partial lens from a viz in a vizboard...";
fil["260"]= "glossary/gdef_adaptive_measure.html@@@adaptive measure@@@When you define a ROLLUP measure computed field, the partitioning criteria of the ROLLUP expression can be fixed or adaptive. You can either partition by an exact field name (fixed), a reference field name (adaptive), or no field name at all (adaptive). Using a reference field allows the partitioning criteria to dynamically adapt to any field of the referenced dataset that is used in the viz. For example, if the partition field is a reference field pointing to the Date dimension, the adaptive measure can be used to partition by any sub-field of Date (Week, Month, Year, and so on...";
fil["261"]= "glossary/gdef_aggregation.html@@@aggregation@@@An aggregation is the result of a function that takes all values of a numeric column, and returns a single value of more significant meaning or measurement. An aggregate function groups the values of multiple rows together based on some defined input expression...";
fil["262"]= "glossary/gdef_amazon_emr.html@@@Amazon EMR@@@Amazon Elastic MapReduce (Amazon EMR) is a Hadoop framework hosted by Amazon Web Services (AWS). It utilizes Amazon Elastic Compute Cloud (Amazon EC2) for compute resources and Amazon Simple Storage Service (Amazon S3) for data storage...";
fil["263"]= "glossary/gdef_amazon_s3.html@@@Amazon S3@@@Amazon Simple Storage Service (Amazon S3) is a data storage service provided by Amazon Web Services (AWS...";
fil["264"]= "glossary/gdef_avro.html@@@Avro@@@Apache Avro is a remote procedure call (RPC) and data serialization framework. Its primary use is to provide a data serialization format for persistent data stored in Hadoop...";
fil["265"]= "glossary/gdef_column.html@@@column@@@A column is a set of data values of a particular data type, with one value for each row in the dataset. Columns provide the structure for composing a row. The terms column and field﻿ are often used interchangeably, although many consider it more correct to use field to refer specifically to the single item that exists at the intersection of one row and one column...";
fil["266"]= "glossary/gdef_computed_field.html@@@computed field@@@A computed field generates its values based on a calculation or condition, and returns a value for each input row. Values are computed based on expressions that can contain values from other fields, constants, mathematical operators, comparison operators, or built-in row functions...";
fil["267"]= "glossary/gdef_continuous.html@@@quantitative@@@Quantitative data can be characterized as a sequence or progression of values with connected data points that can be represented as an unbroken line in a visualization. Quantitative fields usually have values that can be shown in ordered progression, such as height, speed, or duration measurements. Quantitative values are placed on a continuous axis, always displayed from low to high. In Platfora, measure data is always quantitative, but numeric or datetime dimensions can be either quantitative or categorical. Quantitative data is sometimes referred to as continuous dat...";
fil["268"]= "glossary/gdef_csv.html@@@CSV@@@Comma-separated values (CSV) is a plain text file format for describing tabular data. CSV, in general, refers to any file that is plain text (typically ASCII or Unicode characters), has one record per line, has records divided into fields separated by delimiters (typically a comma), and has the same sequence of fields for every record...";
fil["269"]= "glossary/gdef_data_catalog.html@@@data catalog@@@The data catalog is a collection of data items available and visible to Platfora users. Data administrators build the data catalog by defining and modeling datasets in Platfora that point to source data in Hadoop. When users request data from a dataset, that request is materialized in Platfora as a lens. The data catalog shows all of the datasets (data available for request) and lenses (data that is ready for analysis) that have been created by Platfora users...";
fil["270"]= "glossary/gdef_data_source.html@@@data source@@@A data source is a connection to a mount point or directory on an external data server, such as a file system or database server. Platfora currently provides data source adapters for Hive﻿, HDFS, Amazon S3, and MapR FS...";
fil["271"]= "glossary/gdef_dataset.html@@@dataset@@@A dataset is a collection of external data files residing in a data source that can be described in table form (rows and columns). Source data is mapped into Platfora by creating a dataset definition...";
fil["272"]= "glossary/gdef_dfs.html@@@distributed file system@@@A distributed file system (DFS) is any file system that allows access to files from multiple hosts over a computer network. It makes it possible for multiple machines and users to share files and storage resources. HDFS is the primary distributed file system for Hadoop, however Hadoop supports other distributed file systems as well, such as Amazon S3...";
fil["273"]= "glossary/gdef_dimension.html@@@dimension@@@A dimension is a type of field (or a collection of fields) that allows you to analyze a measure from different perspectives to derive meaning from the data. Dimensions are used to summarize, filter, categorize, and group quantitative measure data in order to answer business questions...";
fil["274"]= "glossary/gdef_dimension_dataset.html@@@dimension dataset@@@A type of dataset that has a primary key and contain attributes (additional dimension fields) that describe some aspect of a fact or event record (such as a person, item, date, etc.). Dimension datasets are referenced by a fact dataset...";
fil["275"]= "glossary/gdef_discrete.html@@@categorical@@@Categorical data is data with unconnected data points that can be represented in a visualization as a categorical grouping or individual data point. Categorical data is countable and often finite (for example, the number of products sold or the number of people in a city). In Platfora, categorical values in a visualization are evenly spaced by sort order. By default, dimension fields in a visualization are categorical, but numeric or datetime dimensions can be changed to quantitative. Categorical data is sometimes referred to as discrete dat...";
fil["276"]= "glossary/gdef_drilldown.html@@@drill down@@@Drill down (or drill up) is a data analysis technique for navigating from the most summarized to the most detailed categorization of a particular dimension...";
fil["277"]= "glossary/gdef_event_reference.html@@@event@@@An event is similar to a reference, but the direction of the join is reversed. An event joins the primary key field(s) of a dimension dataset to the corresponding foreign key field(s) in a fact dataset, plus designates a timestamp field for ordering the event records...";
fil["278"]= "glossary/gdef_expression.html@@@expression@@@An expression computes or produces a value by combining fields (or columns), constant values, operators, and functions...";
fil["279"]= "glossary/gdef_fact.html@@@fact dataset@@@In multi-dimentional data models, a fact dataset (or table) contains records (or rows) that represent a single real-world event that has occurred (such as a sales transaction, a page view, a user registration, an airline flight, and so on...";
fil["280"]= "glossary/gdef_field.html@@@field@@@A field is an atomic unit of data that has a name, a value, a data type, and a role of either dimension or measure. When working with visualizations, fields are the same thing as the dimensions and measures used to analyze the dat...";
fil["281"]= "glossary/gdef_filter.html@@@filter@@@A filter is a field value or expression used as a condition for limiting the data that is selected from a lens and shown in a visualization. A filter can be applied to a visualization to exclude (or include) data that meets the filter criteri...";
fil["282"]= "glossary/gdef_focus.html@@@focus@@@A focus sets the central topic for a data exploration and analysis. You set a focus by choosing a single dataset﻿ from the data browser...";
fil["283"]= "glossary/gdef_funnel.html@@@funnel@@@A funnel is a visual analysis type that tracks users  (entities ) behavior across a sequence of events, with each step in the sequence defined as a stage...";
fil["284"]= "glossary/gdef_granularity.html@@@granularity@@@The granularity of data refers to the fineness with which data fields are sub-divided, and the level of detail that data is stored within a dataset or lens. For example, a postal address can be recorded with low granularity with the entire address in one field (address=123 Main St. San Mateo, CA 94403). Or a higher granularity with the fields broken out (address=123 Main St., city=San Mateo, state=CA, zipcode=94403...";
fil["285"]= "glossary/gdef_hadoop.html@@@Hadoop@@@Hadoop is open-source software framework designed for storing and processing large amounts of complex, structured, and semi-structured data. It is a distributed system, meaning it runs on a collection of commodity, shared-nothing servers. Hadoop consists of two key services: a for data storage and for parallel data processing...";
fil["286"]= "glossary/gdef_hdfs.html@@@HDFS@@@Hadoop Distributed File System (HDFS) is the primary storage system for Hadoop applications. It is a distributed file system, meaning it runs on a collection of commodity servers...";
fil["287"]= "glossary/gdef_hive.html@@@Hive@@@Hive is an execution engine for Hadoop that lets you write data queries in an SQL-like language called Hive Query Language (HQL). Hive allows you to create tables by describing the structure of files residing in HDFS...";
fil["288"]= "glossary/gdef_json.html@@@JSON@@@JavaScript Object Notation (JSON) is a data-interchange format based on a subset of the JavaScript Programming Language. JSON is a text format comprised of two basic data structures: objects and arrays...";
fil["289"]= "glossary/gdef_key_field.html@@@key@@@A key is single field (or combination of fields) that uniquely identifies a row in a dataset, similar to a primary key in a relational database. A dataset must have a key defined to be the target of a reference...";
fil["290"]= "glossary/gdef_lens.html@@@lens@@@A lens is a type of data storage that is specific to Platfora. Platfora uses Hadoop as its data source and processing engine to build and store its lenses. Once a lens is built, this prepared data is copied to Platfora, where it is available for analysis. A lens can be thought of as a dynamic, on-demand data mart purpose-built for a specific analysis project...";
fil["291"]= "glossary/gdef_lens_aggregate.html@@@aggregate lens@@@An aggregate lens contains a selection of measure and dimension fields chosen from the focal point of a single fact dataset. A completed or built lens can be thought of as a table that contains aggregated measure data values grouped by the selected dimension values. An aggregate lens can be built from any dataset. There are no special data modeling requirements to build an aggregate lens...";
fil["292"]= "glossary/gdef_lens_event_series.html@@@event series lens@@@An event series lens contains a selection of dimension fields chosen from the focal point of a single dimension dataset, and measure or dimension fields from any fact datasets associated to that dimension dataset. A completed or built lens can be thought of as a table that contains individual event records partitioned by the primary key of the dimension dataset, and ordered by a timestamp field...";
fil["293"]= "glossary/gdef_mapreduce.html@@@MapReduce@@@MapReduce is a data-flow programming model for processing large amounts of data on a cluster of commodity servers. It passes data items from one stage of processing to the next using user-defined criteria (or jobs...";
fil["294"]= "glossary/gdef_measure.html@@@measure@@@A measure is a numeric value representing an aggregation of some dataset metric (such as total dollars sold, average number of users, and so on). To create measures, you add computed fields to a dataset or a lens...";
fil["295"]= "glossary/gdef_reference_field.html@@@reference@@@A reference allows two datasets to be joined together on one or more fields that they share in common. A reference creates a link from a field in one dataset to the primary key of another dataset...";
fil["296"]= "glossary/gdef_regex.html@@@regular expressions@@@Regular expressions, also referred to as regex or regexp, are a standardized collection of special characters and constructs used for matching strings of text. They provide a flexible and precise language for matching particular characters, words, or patterns of characters...";
fil["297"]= "glossary/gdef_rollup_measure.html@@@ROLLUP measure@@@ROLLUP is a modifier to an aggregate expression that allows you to define complex measure expressions, such as windowed, partitioned, or adaptive measure expressions. This is useful when you want to compute an aggregation for a subset of rows within the overall result of a viz query. It allows you to compute things such as running totals, moving averages, benchmark comparisons, rank ordering, percentiles, and so on...";
fil["298"]= "glossary/gdef_row.html@@@row@@@A a row represents a single object or record in a dataset. A dataset or lens consists of rows of columns (or fields...";
fil["299"]= "glossary/gdef_segment.html@@@segment@@@A segment is a special type of dimension field that you can create to group together members of a population that meet some defined common criteria. A segment is a based on members of a dimension dataset (such as customers) that have some behavior in common (such as purchasing a particular product...";
fil["300"]= "glossary/gdef_stage.html@@@stage@@@A stage is a single phase (step) in the process that makes up the funnel. Each stage is based on an event reference in the lens and includes one or more conditions that users must meet to be counted in the stage...";
fil["301"]= "glossary/gdef_visualization.html@@@visualization (viz)@@@A visualization (or viz for short) is a graphical representation of certain data fields chosen from the perspective of a single Platfora lens. It is a query of lens data that is visually rendered based on the types of fields chosen (measure or dimension), their order and placement in the Builder drop zones, and the various appearance encodings applied to the data (color, size, shape, and so on...";
fil["302"]= "glossary/gdef_vizboard.html@@@vizboard@@@A vizboard is the starting point for data analysis, and can be thought of as a dashboard or project workspace. The vizboard is the canvas for discovering and sharing data insights...";
fil["303"]= "glossary/glossary_top.html@@@Glossary@@@The glossary defines Platfora product terminology and concepts...";
fil["304"]= "install/system_requirements/sys_reqs_browsers.html@@@Browser Requirements@@@Users can connect to the Platfora web application using the latest HTML5-compliant web browsers...";
fil["305"]= "install/system_requirements/sys_reqs_ec2_iam_user.html@@@IAM User for Platfora@@@AWS Identity and Access Management (IAM) allows you to create users and groups and control access to AWS services and resources. Platfora recommends creating an IAM user account specifically for use by Platfora. This user must have (at a minimum) the permissions in the AmazonElasticMapReduceFullAccess security policy...";
fil["306"]= "install/system_requirements/sys_reqs_ec2_security.html@@@AWS Security Settings for Platfora@@@Amazon Web Services (AWS) has a number of security features that you can use to protect your AWS account and cloud server instances. This section contains security setting recommendations if you plan to use Amazon Elastic MapReduce (EMR) as the Hadoop implementation for your Platfora cluster...";
fil["307"]= "install/system_requirements/sys_reqs_ec2_security_groups.html@@@EC2 Security Group Settings@@@EC2 security groups allow you to specify firewalling rules for your Amazon elastic cloud computing (EC2) server instances...";
fil["308"]= "install/system_requirements/sys_reqs_hadoop_cluster.html@@@Hadoop Distribution and Resource Requirements@@@Platfora must be able to connect to an existing Hadoop installation. Platfora also requires permissions and resources in the Hadoop source system...";
fil["309"]= "install/system_requirements/sys_reqs_platfora_server.html@@@Platfora Server and Worker Requirements@@@Platfora recommends the following minimum system requirements for Platfora servers. For multi-node installations, the master server and all worker servers must be the same operating system (OS) and system configuration (same amount of memory, CPU, etc...";
fil["310"]= "install/system_requirements/sys_reqs_ports.html@@@Port Configuration Requirements@@@You must open ports in the firewall of your Platfora nodes to allow client access and intra-cluster communications. You also must open ports within your Hadoop cluster to allow access from Platfora. This section lists the default ports required...";
fil["311"]= "install/system_requirements/sys_reqs_ports_hadoop.html@@@Ports to Open on Hadoop Nodes@@@The servers in your Hadoop cluster must allow connections from the Platfora servers. If using Hive as a data source, Platfora must have access to the Hive Metastore server port...";
fil["312"]= "install/system_requirements/sys_reqs_ports_mapr.html@@@Ports to Open on MapR Nodes@@@Your MapR Container Location Database (CLDB), DataNodes and MapReduce JobTracker node must allow connections from the Platfora servers. If using Hive as a data source, Platfora must have access to the Hive Metastore server port...";
fil["313"]= "install/system_requirements/sys_reqs_ports_platfora.html@@@Ports to Open on Platfora Nodes@@@Your Platfora master node must allow HTTP connections from your user network. All nodes must allow connections from the other Platfora nodes in a multi-node cluster...";
fil["314"]= "intro/about_data_pipeline.html@@@Understand the Data Pipeline@@@Once in Platfora, users that are system administrators, data administrators, and analysts work within Platfora s data pipeline. The following diagram depicts the four steps of the Platfora data pipeline...";
fil["315"]= "intro/about_multinode_installs.html@@@Types of Installations@@@You can run on Platfora a single node or scaled out to a multiple node installation...";
fil["316"]= "intro/about_platfora_architecture.html@@@The Platfora Architecture@@@The Platfora server architecture is comprised of three main components: the Lens Builder, the In-Memory Data Server, and the Platfora Application Server...";
fil["317"]= "intro/getting_around_platfora.html@@@The Platfora Application Site Map@@@The Platfora web application has three main functional areas: Data Catalog (data ingest), System (system administration), and Vizboards (data analysis...";
fil["318"]= "intro/intro_to_platfora.html@@@Get an Introduction to Platfora@@@This section introduces you to the Platfora software. You ll learn why Platfora is useful. You ll also get a quick introduction to the architecture, the key components, and the data pipeline...";
fil["319"]= "intro/understand_data.html@@@Understand Dimensions and Measures@@@This section introduces the concept of data dimensions and measures. It is important to understand these concepts as they can impact lens build design and efficiency...";
fil["320"]= "intro/why_platfora.html@@@Why Platfora?@@@Platfora™ enables visual, interactive, in-memory data analysis from raw data in Hadoop...";
fil["321"]= "lens/create_lens.html@@@Create a Lens@@@A lens is always defined from the focal point of a single dataset in the data catalog. Once you have located a dataset that has the data you need, first check and see if there are any existing lenses that you can use. If not, click Create Lens on the dataset details page to define and build a new lens from that dataset...";
fil["322"]= "lens/lens_builder.html@@@Build a Lens (Load Data)@@@To request data from Hadoop and load it into Platfora, you must define and build a lens. A lens can be though of as a dynamic, on-demand data mart purpose-built for a specific analysis project...";
fil["323"]= "lens/about/how_data_is_loaded.html@@@How Data Gets Loaded in Platfora@@@The way you load data into Platfora is by defining and building a lens. A lens is created by choosing fields from the focal point of a single dataset in the Platfora data catalog...";
fil["324"]= "lens/about/lens_best_practices.html@@@Lens Best Practices@@@When you define a lens, you want the selection of fields to be broad enough to support all of the business questions you want to answer. A lens can be used by many visualizations and many users at the same time. On the other hand, you want to constrain the overall size of the lens so that it will fit into the available memory and so queries against the lens are fast...";
fil["325"]= "lens/about/lens_faq.html@@@Lens FAQs@@@A lens is a type of data storage that is specific to Platfora. This topic answers some frequently asked questions about lenses...";
fil["326"]= "lens/about/lens_field_types.html@@@About Lens Field Types@@@Fields are categorized into two basic roles: measures and dimensions. Measure fields are the quantitative data. Dimension fields are the categorical data. A field also has an associated data type, which describes the types of values the field contains (STRING, DATETIME, INTEGER, LONG, FIXED, or DOUBLE). Fields are grouped by the dataset they originate from. As you choose fields for your lens, you will notice that each field has an icon to denote what kind of field it is, and where it originates from...";
fil["327"]= "lens/about/lens_workspace.html@@@About the Lens Builder Panel@@@When you create a new lens or edit an existing one, it opens the lens builder panel. The lens builder is where you choose and confirm the dataset fields that you want in your lens. The lens builder panel looks slightly different depending on the type of lens you are building (aggregate or event series lens). You can click any field to see its definition and description...";
fil["328"]= "lens/build_process/lens_dataset_joins.html@@@Understand How Datasets are Joined@@@This topic explains how datasets are joined together during the lens build process, and what to expect in the resulting lens data. Joins only occur for datasets that have references to other datasets, and fields from the referenced datasets are also included in the lens definition...";
fil["329"]= "lens/build_process/lens_incremental_processing.html@@@Understand Incremental vs Full Lens Builds@@@This section describes how a lens build determines if it needs to process all of the source data (full lens build) or just the new source data that was added since the last time the lens was built (incremental lens build). Incremental lens builds are more desirable because they are faster and use fewer resources...";
fil["330"]= "lens/build_process/lens_input_partition_fields.html@@@Understand Input Partitioning Fields@@@An input partitioning field is a field in a dataset that contains information about how to locate the source files in the remote file system. Defining a filter on these special fields eliminates files from lens build processing as the very first step of the lens build process, as compared to other lens filters which are evaluated later in the process. Defining a lens filter on an input partitioning field is a way to reduce the amount of source data that is scanned by a lens build...";
fil["331"]= "lens/build_process/lens_mapreduce_job_reference.html@@@Understand Lens MapReduce Jobs@@@This topic explains all of the MapReduce jobs or steps that you might possibly see in a lens build, and what is hapening in each step. These steps are listed in the order that they occur in the overall lens build process...";
fil["332"]= "lens/build_process/lens_source_data_input.html@@@Understand Source Data Input to a Lens Build@@@This section describes how Platfora determines what source data files to process for a given lens build...";
fil["333"]= "lens/build_process/understand_lens_builds.html@@@Understand the Lens Build Process@@@The act of building a lens in Platfora generates a series of MapReduce jobs in Hadoop to select, process, aggregate, and prepare the data for use by Platfora s visual query engine, the vizboard. This section explains how source data is selected for processing, what happens to the data during lens build processing, and what resulting data to expect in the lens. By understanding the lens build process, administrators can make decisions to improve lens build performance and ensure the resulting data meets the expectations of business users...";
fil["334"]= "lens/create/agg_lens_default_measure.html@@@Choose the Default Measure@@@The default lens measure is automatically added to new visualizations created from this lens. This allows a default chart to be shown in the vizboard immediately after the data analyst chooses a lens for their viz. If a lens does not have a default measure, the record count of the lens is used as the default measure...";
fil["335"]= "lens/create/agg_lens_dimension_fields.html@@@Choose Dimension Fields (Aggregate Lens)@@@Every aggregate lens needs at least one dimension field. Dimension fields are used to group and filter measure data in an aggregate lens. You can add dimension fields from the currently selected focus dataset or any of its referenced datasets...";
fil["336"]= "lens/create/agg_lens_measure_fields.html@@@Choose Measure Fields (Aggregate Lens)@@@Every aggregate lens needs at least one measure. In Platfora, measure fields are always the result of an aggregate calculation. If you have metric fields in your dataset that you want to use as the basis for quantitative, ad hoc analysis, you must decide how to aggregate those metrics before you build a lens...";
fil["337"]= "lens/create/agg_lens_quick_measures.html@@@Define Quick Measures@@@A quick measure is an aggregation applied to a dimension field to turn it into a measure. You can add quick measures to your lens based on any dimension field in the current focus dataset (for an aggregate lens) or event dataset (for an event series lens...";
fil["338"]= "lens/create/aggregate_lens.html@@@About Aggregate Lenses@@@An aggregate lens can be built from any dataset. There are no special data modeling requirements to build an aggregate lens. Aggregate lenses contain aggregated measure data grouped by the various dimension fields you select from the dataset. Choose this lens type when you want to do ad hoc data analysis...";
fil["339"]= "lens/create/choose_agg_lens_fields.html@@@Choose Aggregate Lens Fields@@@Every aggregate lens must have at least one measure field and one dimension field to be a valid lens. Choose only the fields you need to do your analysis. You can always come back and modify the lens later if you decide you need other fields. You can choose fields from the currently selected dataset, as well as from any datasets it references...";
fil["340"]= "lens/create/choose_esl_lens_fields.html@@@Choose Event Series Lens Fields@@@For an event series lens, field selections are mostly dimension and timestamp fields. You can choose dimension fields from the currently selected dataset, and any fields from the event datasets it references. Measure fields (aggregated variables) are not always applicable to event series analysis, since data is not aggregated in an event series lens...";
fil["341"]= "lens/create/choose_lens_fields.html@@@Choose Lens Fields@@@Choosing fields for a lens depends on the lens type you pick (Aggregate Lens or Event Series Lens), and the type of analysis you plan to do. Aggregate lenses need both measure fields (aggregated variable data) and dimension fields (categorical data). Event series lenses only need dimension fields - measures are optional and not always applicable to event series analysis...";
fil["342"]= "lens/create/esl_lens_measure_fields.html@@@Measure Fields and Event Series Lenses@@@In Platfora, measure fields are always the result of an aggregate calculation. Since event series lenses do not contain aggregated data, measure fields are not always applicable to event series analysis. Measure fields may be included in an event series lens, however they may not show up in the vizboard (depending on the type of analysis you choose...";
fil["343"]= "lens/create/esl_timestamp_fields.html@@@Timestamp Fields and Event Series Lenses@@@Timestamp fields have a special purpose in an event series lens. They are used to order all fact records included in the lens, including fact records coming from multiple datasets. Event series lenses have a global Timestamp field that applies to all event records included in the lens. There are also global Timestamp Date and Timestamp Time references, which can be used to filter records on different granularities of date and time...";
fil["344"]= "lens/create/event_series_lens.html@@@About Event Series Lenses@@@An event series lens can only be built from dimension datasets that have at least one event reference defined in them. It contains non-aggregated fact records, partitioned by the key of the focus dataset, sorted by the time an event occurred. Choose this lens type if you want to do time series analysis, such as funnel paths...";
fil["345"]= "lens/create/lens_date_filters.html@@@Lens Filters on DATETIME Type Fields@@@This section contains special considerations you must make when filtering on datetime type values...";
fil["346"]= "lens/create/lens_expression_troubleshooting.html@@@Troubleshoot Lens Filter Expressions@@@Invalid lens filter expressions don t always result in an error in the web application. Some invalid filter expressions are only caught during a lens build and can cause the lens build to fail. This section has some common lens filter expression mistakes that can cause an error or a lens build failure...";
fil["347"]= "lens/create/lens_filter_expressions.html@@@Write a Filter Expression@@@Lens filters limit the number of records included in a lens. You can define a lens filter on any dimension field included in your lens...";
fil["348"]= "lens/create/lens_filters.html@@@Define Lens Filters@@@One way to limit the size of a lens is to define a filter to constrain the number of rows pulled in from the data source. You can only define filters on dimension fields - one filter condition per field. Filters are evaluated independently during a lens build, so the order in which they are added to the lens does not matter...";
fil["349"]= "lens/create/lens_type.html@@@Choose the Lens Type@@@There are two types of lenses you can create in Platfora: an Aggregate Lens or an Event Series Lens. The type of lens you can choose depends on the underlying characteristics of the dataset you pick as the focus of your lens. The type of lens you build also determines what kinds of visualizations you can create and what kinds of analyses you can perform when using the lens in a vizboard...";
fil["350"]= "lens/create/name_lens.html@@@Name a Lens@@@The first step of defining a lens is to give it a meaningful name. The lens name should help users understand what kind of data they can find in the lens, so they can decide if it will meet their analysis needs. Choose the lens name carefully - you cannot rename a lens after it has been saved or built for the first time...";
fil["351"]= "lens/estimate/about_dataset_profiles.html@@@About Dataset Profiles@@@Dataset profiling takes a sampling of rows (50,000 by default) to determine the characteristics of the data, such as the number of distinct values per field, the distribution of values, and the size of the various fields in the dataset...";
fil["352"]= "lens/estimate/about_lens_estimates.html@@@About Lens Size Estimates@@@Platfora uses the information collected by the dataset profile job to estimate the input and output size of a lens. Dataset profile and estimation information is shown in the lens builder workspace. Lens size estimates dynamically change as you add or remove fields and filters in the lens definition...";
fil["353"]= "lens/estimate/input_size_estimates.html@@@Lens Input Size Estimates@@@Lens input size estimates reflect how much source data will be scanned in the very first stage of a lens build. Lens input size estimates are available on all datasets (event datasets that have not been profiled yet). Input size estimation is applicable to all lens types...";
fil["354"]= "lens/estimate/lens_profile_estimates.html@@@Estimate Lens Size@@@The size of an aggregate lens is determined by how much source data you request (the number of input rows), the number of dimension fields you select, and the cardinality (or number of unique values) of the dimension fields you select. Platfora can help estimate the size of a lens by profiling the data in the dataset...";
fil["355"]= "lens/estimate/output_size_estimates.html@@@Lens Output Size Estimates@@@Lens output size refers to how big the final lens will be after it is built. Lens output size estimates are only available for datasets that have been profiled. Output size estimation is only applicable to aggregate lenses (not to event series lenses...";
fil["356"]= "lens/estimate/profile_a_dataset.html@@@Profile a Dataset@@@You can profile a dataset as long as you have data access and Define Lens from Dataset permissions on the dataset. Profiling a dataset initiates a special lens build to sample the source data and collect its data characteristics...";
fil["357"]= "lens/manage/check_lens_status.html@@@Check the Status of a Lens Build@@@Depending on the size of the source data requested, it may take a while to process the requested data in Hadoop to build a Platfora lens. The lens is not available for use in visualizations until the lens build is complete. You can check the status of a lens build on the System page...";
fil["358"]= "lens/manage/delete_lens.html@@@Delete or Unbuild a Lens@@@Deleting or unbuilding a lens is a way to free up space in Platfora for lenses that are no longer needed or used. Deleting a lens removes the lens definition as well as the lens data. Unbuilding a lens only removes the lens data (but keeps the lens definition in case you want to rebuild the lens at a later time...";
fil["359"]= "lens/manage/edit_lens.html@@@Edit a Lens Definition@@@After working with a lens, you may realize that there are fields that you do not need, or additional fields that you d like to add to the lens. You can edit the lens definition to add or remove fields as long as you have data access and edit permissions on the lens. Lens definition changes will not be available in a vizboard until the lens is rebuilt...";
fil["360"]= "lens/manage/manage_lenses.html@@@Manage Lenses@@@After a lens is defined, you can edit it, build it, check its status, update/rebuild it (refresh its data), or delete it. Lenses can be managed from the Data Catalog or System page...";
fil["361"]= "lens/manage/query_lens.html@@@Query a Lens with Programmatic Query Acces (PQA)@@@This section describes support for querying lenses using Platfora s expression language and programmatic query access...";
fil["362"]= "lens/manage/update_lens.html@@@Refresh Lens Data@@@Once a lens has been built, you can update it to refresh its data it at any time. You may want to update a lens if new data has arrived in the source Hadoop system, or if you have changed the lens definition to include additional fields. Depending on what has changed since the last build, subsequent lens builds are usually a lot faster...";
fil["363"]= "lens/notifications/add_lens_notification.html@@@Add a Lens Notification Rule@@@Define a lens notification rule so Platfora sends an email to notify users when the data in a lens build meets specified criteria. You can define multiple rules per lens...";
fil["364"]= "lens/notifications/disable_lens_notification.html@@@Disable a Lens Notification Rule@@@Disabling a lens notification rule allows you temporarily stop notifications while retaining the logic defined in the notification rule...";
fil["365"]= "lens/notifications/lens_notifications.html@@@Manage Lens Notifications@@@You can configure a lens so Platfora sends an email message to users when it detects an anomaly in lens data. Do this by defining a lens notification. You might want to define a lens notification so data analysts know when to view a vizboard to analyze the data further...";
fil["366"]= "lens/schedule/about_lens_schedule.html@@@About Lens Schedules@@@When you create or edit a schedule, you define one or more rules. A rule is a set of times and days that specify when to build a lens. You might want to create multiple rules so the lens builds at different times on different days. For example, you might want to build the lens at 1:00 a.m. on weekdays, and 8:00 p.m. on weekends...";
fil["367"]= "lens/schedule/define_lens_schedule.html@@@Create a Lens Schedule@@@You can configure a schedule for a lens so it is built at specific times on specific days. You define the lens schedule when you edit the lens. The schedule is saved whether or not you save your changes on the lens page...";
fil["368"]= "lens/schedule/lens_schedule.html@@@Schedule Lens Builds@@@You can configure a lens to be built at specific times on specific days. By default, lenses are built on demand, but when you define a schedule for a lens, it is built automatically at the times and days specified in the schedule. You might want to define a schedule so the lens is built nightly, outside of regular working hours...";
fil["369"]= "lens/schedule/view_all_lens_schedules.html@@@View All Scheduled Lens Builds@@@Users with the role of System Administrator can view all scheduled lens builds. Additionally, they can pause (and later resume) a schedule lens build, which might be useful during maintenance windows or a time of unusually high lens build demand...";
fil["370"]= "preface/contact_info.html@@@Contact Platfora Support@@@For technical support, you can send an email to: support@platfora.com Or visit the Platfora support site for the most up-to-date product news, knowledge base articles, tips and tricks, and training...";
fil["371"]= "preface/copyright_info.html@@@Copyright Notices@@@Copyright © 2012-14 Platfora Corporation. All rights reserved. Platfora believes the information in this publication is accurate as of its publication date. The information is subject to change...";
fil["372"]= "reference/expression_language/agg_functions_top.html@@@Aggregate Functions@@@An aggregate function groups the values of multiple rows together based on some defined input expression. Aggregate functions return one value for a group of rows, and are only valid for defining measures in Platfora. Aggregate functions cannot be combined with row functions...";
fil["373"]= "reference/expression_language/expression_errors.html@@@Common Causes of Expression Errors@@@You cannot save a computed field that contains an error in the expression syntax. If your expression is not valid syntax, you will get an error message. This section describes some common expression errors and possible causes to investigate...";
fil["374"]= "reference/expression_language/expression_quickref.html@@@Expression Builder Dictionary@@@An expression is a combination of columns (or fields), constant values, operators, and functions used to evaluate, transform, or produce a value. Simple expressions can be combined to make more complex expressions. This quick reference describes the functions and operators that can be used to write expressions...";
fil["375"]= "reference/expression_language/expression_reference_top.html@@@Expression and Query Language Reference@@@An expression computes or produces a value by combining fields (or columns), constant values, operators, and functions. Platfora has a built-in expression language. You use the language s functions and operators to create a computed field...";
fil["376"]= "reference/expression_language/function_array_contains.html@@@ARRAY_CONTAINS@@@ARRAY_CONTAINS is a row function that performs a whole string match against a string containing delimited values and returns a 1 or 0 depending on whether or not the string contains the search value...";
fil["377"]= "reference/expression_language/function_avg.html@@@AVG@@@AVG is an aggregate function that returns the average of all valid numeric values. It sums all values in the provided expression and divides by the number of valid (NOT NULL) rows. If you want to compute an average that includes all values in the row count (including NULL values), you can use a SUM/COUNT expression instead...";
fil["378"]= "reference/expression_language/function_case.html@@@CASE@@@CASE is a row function that evaluates each row in the dataset according to one or more input conditions, and outputs the specified result when the input conditions are met...";
fil["379"]= "reference/expression_language/function_cidrmatch.html@@@CIDR_MATCH@@@CIDR_MATCH is a row function that compares two STRING arguments representing a CIDR mask and an IP address, and returns 1 if the IP address falls within the specified subnet mask or 0 if it does not...";
fil["380"]= "reference/expression_language/function_coalesce.html@@@COALESCE@@@COALESCE is a row function that returns the first valid value (NOT NULL value) from a comma-separated list of expressions...";
fil["381"]= "reference/expression_language/function_concat.html@@@CONCAT@@@CONCAT is a row function that returns a string by concatenating (combining together) the results of multiple string expressions...";
fil["382"]= "reference/expression_language/function_count.html@@@COUNT@@@COUNT is an aggregate function that returns the number of rows in a dataset...";
fil["383"]= "reference/expression_language/function_countvalid.html@@@COUNT_VALID@@@COUNT_VALID is an aggregate function that returns the number of rows for which the given expression is valid (excludes NULL values...";
fil["384"]= "reference/expression_language/function_date_add.html@@@DATE_ADD@@@DATE_ADD is a row function that adds the specified time interval to a DATETIME value...";
fil["385"]= "reference/expression_language/function_daysbetween.html@@@DAYS_BETWEEN@@@DAYS_BETWEEN is a row function that calculates the whole number of days (ignoring time) between two DATETIME values (value1-value2...";
fil["386"]= "reference/expression_language/function_dense_rank.html@@@DENSE_RANK@@@DENSE_RANK is an aggregate function that assigns the rank (position) of each row in a group (partition) of rows and does not skip rank numbers in the event of tie. The rank of a row is one plus the number of distinct ranks that come before the row. DENSE_RANK must be used with the ROLLUP function, which acts as a modifier for DENSE_RANK. Use a column in the ROLLUP order by clause to determine on which column to determine the ranking...";
fil["387"]= "reference/expression_language/function_distinct.html@@@DISTINCT@@@DISTINCT is an aggregate function that returns the number of distinct values for the given expression...";
fil["388"]= "reference/expression_language/function_div.html@@@DIV@@@DIV is a row function that divides two LONG values and returns a quotient value of type LONG (the result is truncated to 0 decimal places...";
fil["389"]= "reference/expression_language/function_epochms_todate.html@@@EPOCH_MS_TO_DATE@@@EPOCH_MS_TO_DATE is a row function that converts LONG values to DATETIME values, where the input number represents the number of milliseconds since the epoch...";
fil["390"]= "reference/expression_language/function_exp.html@@@EXP@@@EXP is a row function that raises the mathematical constant e to the power (exponent) of a numeric value and returns a value of type DOUBLE...";
fil["391"]= "reference/expression_language/function_extract.html@@@EXTRACT@@@EXTRACT is a row function that returns the specified portion of a DATETIME value...";
fil["392"]= "reference/expression_language/function_extract_cookie.html@@@EXTRACT_COOKIE@@@EXTRACT_COOKIE is a row function that extracts the value of the given cookie identifier from a semi-colon delimited list of cookie key=value pairs. This function can be used to extract a particular cookie value from a combined web access log Cookie column...";
fil["393"]= "reference/expression_language/function_extract_value.html@@@EXTRACT_VALUE@@@EXTRACT_VALUE is a row function that extracts the value for the given key from a string containing delimited key/value pairs...";
fil["394"]= "reference/expression_language/function_filename.html@@@FILE_NAME@@@FILE_NAME is a row function that returns the original file name from the source file system. This is useful when the source data that comprises a dataset comes from multiple files, and there is useful information in the file names themselves (such as dates or server names). You can use FILE_NAME in combination with other string processing functions to extract useful information from the file name...";
fil["395"]= "reference/expression_language/function_filepath.html@@@FILE_PATH@@@FILE_PATH is a row function that returns the full URI path from the source file system. This is useful when the source data that comprises a dataset comes from multiple files, and there is useful information in the directory names or file names themselves (such as dates or server names). You can use FILE_PATH in combination with other string processing functions to extract useful information from the file path...";
fil["396"]= "reference/expression_language/function_floor.html@@@FLOOR@@@FLOOR is a row function that returns the largest integer that is less than or equal to the input argument...";
fil["397"]= "reference/expression_language/function_hash.html@@@HASH@@@HASH is a row function that evenly partitions data values into the specified number of buckets. It creates a hash of the input value and assigns that value a bucket number. Equal values will always hash to the same bucket number...";
fil["398"]= "reference/expression_language/function_hextoip.html@@@HEX_TO_IP@@@HEX_TO_IP is a row function that converts a hexadecimal-encoded STRING to a text representation of an IP address...";
fil["399"]= "reference/expression_language/function_hoursbetween.html@@@HOURS_BETWEEN@@@HOURS_BETWEEN is a row function that calculates the whole number of hours (ignoring minutes, seconds, and milliseconds) between two DATETIME values (value1-value2...";
fil["400"]= "reference/expression_language/function_instr.html@@@INSTR@@@INSTR is a row function that returns an integer indicating the position of a character within a string that is the first character of the occurrence of a substring. Platfora s INSTR function is similar to the FIND function in Excel, except that the first letter is position 0 and the order of the arguments is reversed...";
fil["401"]= "reference/expression_language/function_isvalid.html@@@IS_VALID@@@IS_VALID is a row function that returns 0 if the returned value is NULL, and 1 if the returned value is NOT NULL. This is useful for computing other calculations where you want to exclude NULL values (such as when computing averages...";
fil["402"]= "reference/expression_language/function_java_string.html@@@JAVA_STRING@@@JAVA_STRING is a row function that returns the unescaped version of a Java unicode character escape sequence as a string value. This is useful when you want to specify unicode characters in an expression. For example, you can use JAVA_STRING to specify the unicode value representing a control character...";
fil["403"]= "reference/expression_language/function_join_strings.html@@@JOIN_STRINGS@@@JOIN_STRINGS is a row function that returns a string by concatenating (combining together) the results of multiple values with the separator in between each non-null value...";
fil["404"]= "reference/expression_language/function_json_array_contains.html@@@JSON_ARRAY_CONTAINS@@@JSON_ARRAY_CONTAINS is a row function that performs a whole string match against a string formatted as a JSON array and returns a 1 or 0 depending on whether or not the string contains the search value...";
fil["405"]= "reference/expression_language/function_json_double.html@@@JSON_DOUBLE@@@JSON_DOUBLE is a row function that extracts a DOUBLE value from a field in a JSON object...";
fil["406"]= "reference/expression_language/function_json_fixed.html@@@JSON_FIXED@@@JSON_FIXED is a row function that extracts a FIXED value from a field in a JSON object...";
fil["407"]= "reference/expression_language/function_json_integer.html@@@JSON_INTEGER@@@JSON_INTEGER is a row function that extracts an INTEGER value from a field in a JSON object...";
fil["408"]= "reference/expression_language/function_json_long.html@@@JSON_LONG@@@JSON_LONG is a row function that extracts a LONG value from a field in a JSON object...";
fil["409"]= "reference/expression_language/function_json_string.html@@@JSON_STRING@@@JSON_STRING is a row function that extracts a STRING value from a field in a JSON object...";
fil["410"]= "reference/expression_language/function_length.html@@@LENGTH@@@LENGTH is a row function that returns the count of characters in a string value...";
fil["411"]= "reference/expression_language/function_ln.html@@@LN@@@LN is a row function that returns the natural logarithm of a number. The natural logarithm is the logarithm to the base e, where e (Euler s number) is a mathematical constant approximately equal to 2.718281828. The natural logarithm of a number x is the power to which the constant e must be raised in order to equal x...";
fil["412"]= "reference/expression_language/function_max.html@@@MAX@@@MAX is an aggregate function that returns the biggest value from the given input expression...";
fil["413"]= "reference/expression_language/function_millisecondsbetween.html@@@MILLISECONDS_BETWEEN@@@MILLISECONDS_BETWEEN is a row function that calculates the whole number of milliseconds between two DATETIME values (value1-value2...";
fil["414"]= "reference/expression_language/function_min.html@@@MIN@@@MIN is an aggregate function that returns the smallest value from the given input expression...";
fil["415"]= "reference/expression_language/function_minutesbetween.html@@@MINUTES_BETWEEN@@@MINUTES_BETWEEN is a row function that calculates the whole number of minutes (ignoring seconds and milliseconds) between two DATETIME values (value1-value2...";
fil["416"]= "reference/expression_language/function_mod.html@@@MOD@@@MOD is a row function that divides two LONG values and returns the remainder value of type LONG (the result is truncated to 0 decimal places...";
fil["417"]= "reference/expression_language/function_now.html@@@NOW@@@NOW is a scalar function that returns the current system date and time as a DATETIME value. It can be used in other expressions involving DATETIME type fields, such as , , or . Note that the value of NOW is only evaluated at the time a lens is built (it is not re-evaluated with each query...";
fil["418"]= "reference/expression_language/function_ntile.html@@@NTILE@@@NTILE is a windowing aggregate function that divides a partitioned group of rows into the specified number of buckets, and returns the bucket number to which the current row belongs. NTILE must be used within a ROLLUP expression...";
fil["419"]= "reference/expression_language/function_pack_values.html@@@PACK_VALUES@@@PACK_VALUES is a row function that returns multiple output values packed into a single string of key/value pairs separated by the Platfora default key and pair separators. This is useful when the OUTPUT clause of a PARTITION expression returns multiple output values. The string returned is in a format that can be read by the EXTRACT_VALUE function. PACK_VALUES uses the same key and pair separator values that EXTRACT_VALUE uses (the Unicode escape sequences u0003 and u0002, respectively...";
fil["420"]= "reference/expression_language/function_partition.html@@@PARTITION@@@PARTITION is an event series processing language that partitions the rows of a dataset, orders the rows sequentially (typically by a timestamp), and searches for matching patterns in a set of rows. Computed fields that are defined in a dataset using a PARTITION expression are considered event series processing computed fields. Event series processing computed fields are processed differently than regular computed fields. Instead of computing values from the input of a single row, they compute values from inputs of multiple rows in the dataset...";
fil["421"]= "reference/expression_language/function_pow.html@@@POW@@@POW is a row function that raises the a numeric value to the power (exponent) of another numeric value and returns a value of type DOUBLE...";
fil["422"]= "reference/expression_language/function_rank.html@@@RANK@@@RANK is an aggregate function that assigns the rank (position) of each row in a group (partition) of rows and skips rank numbers in the event of tie. The rank of a row is one plus the number of ranks that come before the row. RANK must be used with the ROLLUP function, which acts as a modifier for RANK. Use a column in the ROLLUP order by clause to determine on which column to determine the ranking...";
fil["423"]= "reference/expression_language/function_regex.html@@@REGEX@@@REGEX is a row function that performs a whole string match against a string value with a regular expression and returns the portion of the string matching the first capturing group of the regular expression...";
fil["424"]= "reference/expression_language/function_regex_replace.html@@@REGEX_REPLACE@@@REGEX_REPLACE is a row function that evaluates a string value against a regular expression to determine if there is a match, and replaces matched strings with the specified replacement value...";
fil["425"]= "reference/expression_language/function_rollup.html@@@ROLLUP@@@ROLLUP is a modifier to an aggregate function that turns a regular aggregate function into a windowed, partitioned, or adaptive aggregate function. This is useful when you want to compute an aggregation over a subset of rows within the overall result of a viz query...";
fil["426"]= "reference/expression_language/function_round.html@@@ROUND@@@ROUND is a row function that rounds a DOUBLE value to the specified number of decimal places...";
fil["427"]= "reference/expression_language/function_rownumber.html@@@ROW_NUMBER@@@ROW_NUMBER is a windowing aggregate function that assigns a unique, sequential number to each row in a group (partition) of rows, starting at 1 for the first row in each partition. ROW_NUMBER must be used within a ROLLUP expression, which acts as a modifier for ROW_NUMBER. Use a column in the ROLLUP order by clause to determine on which column to determine the row number...";
fil["428"]= "reference/expression_language/function_secondsbetween.html@@@SECONDS_BETWEEN@@@SECONDS_BETWEEN is a row function that calculates the whole number of seconds (ignoring milliseconds) between two DATETIME values (value1-value2...";
fil["429"]= "reference/expression_language/function_split.html@@@SPLIT@@@SPLIT is a row function that breaks down a delimited input string into sections and returns the specified section of the string. A section is considered any sub-string between the specified delimiter...";
fil["430"]= "reference/expression_language/function_stddev.html@@@STDDEV@@@STDDEV is an aggregate function that calculates the population standard deviation for a group of numeric values. Standard deviation is the square root of the variance...";
fil["431"]= "reference/expression_language/function_substring.html@@@SUBSTRING@@@SUBSTRING is a row function that returns the specified characters of a string value based on the given start and end position...";
fil["432"]= "reference/expression_language/function_sum.html@@@SUM@@@SUM is an aggregate function that returns the total of all values from the given input expression...";
fil["433"]= "reference/expression_language/function_tocurrency.html@@@TO_CURRENCY@@@Use the TO_FIXED function instead...";
fil["434"]= "reference/expression_language/function_todate.html@@@TO_DATE@@@TO_DATE is a row function that converts STRING values to DATETIME values, and specifies the format of the date and time elements in the string...";
fil["435"]= "reference/expression_language/function_todouble.html@@@TO_DOUBLE@@@TO_DOUBLE is a row function that converts STRING, INTEGER, LONG, or DOUBLE values to DOUBLE (decimal) values...";
fil["436"]= "reference/expression_language/function_tofixed.html@@@TO_FIXED@@@TO_FIXED is a row function that converts STRING, INTEGER, LONG, or DOUBLE values to fixed-decimal values. Using a FIXED data type to represent monetary values allows you to calculate and aggregate monetary values with accuracy to a ten-thousandth of a monetary unit...";
fil["437"]= "reference/expression_language/function_toint.html@@@TO_INT@@@TO_INT is a row function that converts STRING, INTEGER, LONG, or DOUBLE values to INTEGER (whole number) values. When converting DOUBLE values, everything after the decimal will be truncated (not rounded up or down...";
fil["438"]= "reference/expression_language/function_tolong.html@@@TO_LONG@@@TO_LONG is a row function that converts STRING, INTEGER, LONG, or DOUBLE values to LONG (whole number) values. When converting DOUBLE values, everything after the decimal will be truncated (not rounded up or down...";
fil["439"]= "reference/expression_language/function_tolower.html@@@TO_LOWER@@@TO_LOWER is a row function that converts all alphabetic characters in a string to lower case...";
fil["440"]= "reference/expression_language/function_tostring.html@@@TO_STRING@@@TO_STRING is a row function that converts values of other data types to STRING (character) values...";
fil["441"]= "reference/expression_language/function_toupper.html@@@TO_UPPER@@@TO_UPPER is a row function that converts all alphabetic characters in a string to upper case...";
fil["442"]= "reference/expression_language/function_trim.html@@@TRIM@@@TRIM is a row function that removes leading and trailing spaces from a string value...";
fil["443"]= "reference/expression_language/function_trunc.html@@@TRUNC@@@TRUNC is a row function that truncates a DATETIME value to the specified format...";
fil["444"]= "reference/expression_language/function_url_authority.html@@@URL_AUTHORITY@@@URL_AUTHORITY is a row function that returns the authority portion of a URL string. The authority portion of a URL is the part that has the information on how to locate and connect to the server...";
fil["445"]= "reference/expression_language/function_url_fragment.html@@@URL_FRAGMENT@@@URL_FRAGMENT is a row function that returns the fragment portion of a URL string...";
fil["446"]= "reference/expression_language/function_url_host.html@@@URL_HOST@@@URL_HOST is a row function that returns the host, domain, or IP address portion of a URL string...";
fil["447"]= "reference/expression_language/function_url_path.html@@@URL_PATH@@@URL_PATH is a row function that returns the path portion of a URL string...";
fil["448"]= "reference/expression_language/function_url_port.html@@@URL_PORT@@@URL_PORT is a row function that returns the port portion of a URL string...";
fil["449"]= "reference/expression_language/function_url_protocol.html@@@URL_PROTOCOL@@@URL_PROTOCOL is a row function that returns the protocol (or URI scheme name) portion of a URL string...";
fil["450"]= "reference/expression_language/function_url_query.html@@@URL_QUERY@@@URL_QUERY is a row function that returns the query portion of a URL string...";
fil["451"]= "reference/expression_language/function_urldecode.html@@@URLDECODE@@@URLDECODE is a row function that decodes a string that has been encoded with the application/x-www-form-urlencoded media type. URL encoding, also known as percent-encoding, is a mechanism for encoding information in a Uniform Resource Identifier (URI). When sent in an HTTP GET request, application/x-www-form-urlencoded data is included in the query component of the request URI. When sent in an HTTP POST request, the data is placed in the body of the message, and the name of the media type is included in the message Content-Type header...";
fil["452"]= "reference/expression_language/function_variance.html@@@VARIANCE@@@VARIANCE is an aggregate function that calculates the population variance for a group of numeric values. Variance measures the amount by which all values in a group vary from the average value of the group. Data with low variance contains values that are identical or similar. Data with high variance contains values that are not similar. Variance is calculated as the average of the squares of the deviations from the mean. Squaring the deviations ensures that negative and positive deviations do not cancel each other out...";
fil["453"]= "reference/expression_language/function_yeardiff.html@@@YEAR_DIFF@@@YEAR_DIFF is a row function that calculates the fractional number of years between two DATETIME values (value1-value2...";
fil["454"]= "reference/expression_language/operators_comparison.html@@@Comparison Operators@@@Comparison operators are used to compare the equivalency of two expressions of the same data type. The result of a comparison expression is a Boolean value (returns 1 for true, 0 for false, or NULL for invalid). Boolean expressions are most often used to specify data processing conditions or filter criteri...";
fil["455"]= "reference/expression_language/operators_logical.html@@@Logical Operators@@@You use logical operators in a WHERE clause to test the truth of some condition. They return a Boolean value of TRUE (1) or FALSE (O). The result of a comparison expression is a Boolean value (returns 1 for true, 0 for false, or NULL for invalid). Logical expressions are most often used to specify filter criteri...";
fil["456"]= "reference/expression_language/operators_math.html@@@Arithmetic Operators@@@Arithmetic operators perform basic math operations on two expressions of the same data type resulting in a numeric value. The plus (+) and minus (-) operators can also be used to perform arithmetic operations on DATETIME values...";
fil["457"]= "reference/expression_language/row_conversion_functions_top.html@@@Data Type Conversion Functions@@@Data type conversion functions allow you to cast data values from one data type to another. These functions are used implicitly whenever you set the data type of a field or column in the Platfora user interface. The supported data types are: INTEGER, LONG, DOUBLE, FIXED, DATETIME, and STRING...";
fil["458"]= "reference/expression_language/row_date_functions_top.html@@@Date and Time Functions@@@Date and time functions allow you to manipulate and transform datetime values, such as calculating time differences between two datetime values, or extracting a portion of a datetime value...";
fil["459"]= "reference/expression_language/row_general_functions_top.html@@@General Processing Functions@@@General processing functions allow you to perform basic data evaluation operations, such as checking for NULL values or processing values based on certain input conditions...";
fil["460"]= "reference/expression_language/row_ip_functions_top.html@@@IP Address Functions@@@IP address functions allow you to manipulate and transform STRING data consisting of IP address values...";
fil["461"]= "reference/expression_language/row_math_functions_top.html@@@Math Functions@@@Math functions allow you to perform basic math calculations on numeric values. You can also use arithmetic operators to perform simple math calculations...";
fil["462"]= "reference/expression_language/row_string_functions_top.html@@@String Functions@@@String functions allow you to manipulate and transform textual data, such as combining string values or extracting a portion of a string value...";
fil["463"]= "reference/expression_language/row_url_functions_top.html@@@URL Functions@@@URL functions allow you to extract different portions of a URL string, and decode text that is URL-encoded...";
fil["464"]= "reference/expression_language/window_functions_top.html@@@ROLLUP and Window Functions@@@Window functions can only be used in conjunction with ROLLUP. ROLLUP is a modifier to an aggregate expression that determines the partitioning and ordering of a rowset before the associated aggregate function or window function is applied. ROLLUP defines a window or user-specified set of rows within a query result set. A window function then computes a value for each row in the window. You can use window functions to compute aggregated values such as moving averages, cumulative aggregates, running totals, or a top N per group results...";
fil["465"]= "reference/expression_language/udf/add_udf_top.html@@@User Defined Functions (UDFs)@@@User defined functions (UDFs) allow you to define your own per-row processing logic, and then expose that functionality to users in the Platfora application expression builder...";
fil["466"]= "reference/expression_language/udf/install_udf_class.html@@@Adding a UDF to the Platfora Expression Builder@@@After you have written and compiled a user defined function (UDF) Java class, you must install your class on the Platfora master server and enable it so that it can be seen and used in the Platfora expression builder...";
fil["467"]= "reference/expression_language/udf/write_udf_java_program.html@@@Writing a Platfora UDF Java Program@@@User defined functions (UDFs) are written in the Java programming language and implement the Platfora-provided Java interface, com.platfora.udf.UserDefinedFunction...";
fil["468"]= "reference/platfora_properties/advanced_properties_top.html@@@Advanced Properties@@@The advanced properties allow you to configure some advanced internal Platfora processes. Most properties should be changed only when instructed by customer support. Note that some advanced properties descriptions are included in their own sections...";
fil["469"]= "reference/platfora_properties/com.platfora.schema.version.html@@@com.platfora.schema.version@@@The version of the Platfora database catalog used with postgres...";
fil["470"]= "reference/platfora_properties/com.platfora.version.build.date.html@@@com.platfora.version.build.date@@@The data Platfora built this version of the software...";
fil["471"]= "reference/platfora_properties/com.platfora.version.full.html@@@com.platfora.version.full@@@The version number and the build date...";
fil["472"]= "reference/platfora_properties/emrs3_properties_top.html@@@Amazon EMR and S3 Properties@@@The Amazon EMR and S3 properties allow you to configure how Platfora connects to AWS and initializes an EMR cluster...";
fil["473"]= "reference/platfora_properties/expressions_properties_top.html@@@Expressions Properties@@@The expressions properties allow you to configure how Platfora handles some built-in functions and user defined functions (UDFs) in its expression language...";
fil["474"]= "reference/platfora_properties/general_properties_top.html@@@General Properties@@@The general properties display some properties that were configured during setup and also allows you to configure basic settings, such as compressing lens files. Note that some general properties descriptions are included in their own sections...";
fil["475"]= "reference/platfora_properties/general_quickref.html@@@Bootstrap Configuration Properties@@@The installation process collects several bootstrap configuration properties...";
fil["476"]= "reference/platfora_properties/headerfooter_properties_top.html@@@Custom Header and Footer Properties@@@These properties allow you to configure a custom header and footer in the Platfora application. These are in addition to the application s own header and footer...";
fil["477"]= "reference/platfora_properties/lensbuilder_properties_top.html@@@Lens Builder Properties@@@The lens builder properties allow you to configure how the lens builder process behaves when building lenses...";
fil["478"]= "reference/platfora_properties/platfora.S3.accesskey.html@@@platfora.S3.accesskey@@@Enter your Amazon S3 account access key ID...";
fil["479"]= "reference/platfora_properties/platfora.S3.secretkey.html@@@platfora.S3.secretkey@@@Enter your Amazon S3 secret key...";
fil["480"]= "reference/platfora_properties/platfora.admin.buildSummarySince.html@@@platfora.admin.buildSummarySince@@@The location on the local disk where Platfora is installed...";
fil["481"]= "reference/platfora_properties/platfora.build.dictionary.cutoff.html@@@platfora.build.dictionary.cutoff@@@Dictionaries with no more than this number of entries are joined to in-memory in the mapper...";
fil["482"]= "reference/platfora_properties/platfora.build.dimmap.cutoff.html@@@platfora.build.dimmap.cutoff@@@Dimension key maps with no more than this number of total bytes are joined to in-memory in the mapper...";
fil["483"]= "reference/platfora_properties/platfora.build.distinct.partitionsize.html@@@platfora.build.distinct.partitionsize@@@Used to determine the number of distinct partitions for a lens build...";
fil["484"]= "reference/platfora_properties/platfora.build.limit.space.html@@@platfora.build.limit.space@@@Specify the maximum amount of space Platfora uses on DFS while building a lens, in bytes...";
fil["485"]= "reference/platfora_properties/platfora.build.limit.time.html@@@platfora.build.limit.time@@@Specify the maximum amount of time Platfora uses for building a lens, in seconds...";
fil["486"]= "reference/platfora_properties/platfora.buildCleaner.force.threshold.html@@@platfora.buildCleaner.force.threshold@@@Enter the number of times the build cleaner waits for an opportunity to run before running, even if a lens is currently being built or queried against...";
fil["487"]= "reference/platfora_properties/platfora.buildCleaner.interval.html@@@platfora.buildCleaner.interval@@@Enter how much time to wait before the build cleaner runs again to remove unused lens files...";
fil["488"]= "reference/platfora_properties/platfora.buildCleaner.purged.expiry.html@@@platfora.buildCleaner.purged.expiry@@@Enter the amount of time in minutes the build cleaner waits before removing lens build files in HDFS that have already been unbuilt and deleted from Platfora s local disk...";
fil["489"]= "reference/platfora_properties/platfora.builder.abort.error.threshold.html@@@platfora.builder.abort.error.threshold@@@The maximum number of lens data quality error rows allowed per lens build. If this limit is exceeded for a lens build job, then the lens build will abort and fail...";
fil["490"]= "reference/platfora_properties/platfora.builder.chunk.size.html@@@platfora.builder.chunk.size@@@Enter the maximum number of rows that are stored in a single file within a lens...";
fil["491"]= "reference/platfora_properties/platfora.builder.combine.split.sort.percent.html@@@platfora.builder.combine.split.sort.percent@@@Full Description Default 0.80f Value Range/Type Float Configurable in Web Application Yes Node Override No Restart Requirements Requires Platfora server restart...";
fil["492"]= "reference/platfora_properties/platfora.builder.dictionary.deduplication.cutoff.html@@@platfora.builder.dictionary.deduplication.cutoff@@@Enter the maximum input data size above which Platfora dedupes...";
fil["493"]= "reference/platfora_properties/platfora.builder.dictionary.partitioning.cutoff.html@@@platfora.builder.dictionary.partitioning.cutoff@@@Enter the maximum column cardinality above which Platfora partitions...";
fil["494"]= "reference/platfora_properties/platfora.builder.dictionary.partitioning.factor.html@@@platfora.builder.dictionary.partitioning.factor@@@Enter the number of dictionary partitions Platfora creates for large dictionaries...";
fil["495"]= "reference/platfora_properties/platfora.builder.encoding.skew.values.max.html@@@platfora.builder.encoding.skew.values.max@@@Maximum number of skewed values to detect and handle...";
fil["496"]= "reference/platfora_properties/platfora.builder.error.rows.threshold.html@@@platfora.builder.error.rows.threshold@@@The maximum number of lens data quality error rows that will be recorded per map task. If this limit is exceeded, then just that map task will stop writing its data quality log file...";
fil["497"]= "reference/platfora_properties/platfora.builder.file.skip.modified.age.html@@@platfora.builder.file.skip.modified.age@@@Skip the files modified within the last n seconds. This is intended for use with EMR s Simple Server Systems (S3...";
fil["498"]= "reference/platfora_properties/platfora.builder.global.lens.build.file.limit.html@@@platfora.builder.global.lens.build.file.limit@@@Enter the maximum number of files Platfora creates in HDFS for all lens builds...";
fil["499"]= "reference/platfora_properties/platfora.builder.incremental.dimensions.html@@@platfora.builder.incremental.dimensions@@@Choose whether or not to perform an incremental lens build instead of a full rebuild when new source files are added to a referenced dataset...";
fil["500"]= "reference/platfora_properties/platfora.builder.lens.build.concurrency.html@@@platfora.builder.lens.build.concurrency@@@Enter the maximum number of lens builds that can be active at the same time...";
fil["501"]= "reference/platfora_properties/platfora.builder.lens.build.file.limit.html@@@platfora.builder.lens.build.file.limit@@@Enter the maximum number of files Platfora creates in HDFS for each lens build...";
fil["502"]= "reference/platfora_properties/platfora.builder.record.data.quality.errors.html@@@platfora.builder.record.data.quality.errors@@@Enables or disables the logging of rows containing lens data quality errors...";
fil["503"]= "reference/platfora_properties/platfora.builder.record.error.filepaths.html@@@platfora.builder.record.error.filepaths@@@Enables or disables the logging of file path information for each line in a data quality report file...";
fil["504"]= "reference/platfora_properties/platfora.builder.reduce.max.count.distinct.keys.html@@@platfora.builder.reduce.max.count.distinct.keys@@@Maximum number of unique values in count distinct...";
fil["505"]= "reference/platfora_properties/platfora.builder.sample.average.row.size.bytes.html@@@platfora.builder.sample.average.row.size.bytes@@@Enter the average number of bytes used per row in the Platfora datasets...";
fil["506"]= "reference/platfora_properties/platfora.builder.sample.cutoff.safety.factor.html@@@platfora.builder.sample.cutoff.safety.factor@@@Multiplier used as a safety factor to calculate sample mapper row cutoff...";
fil["507"]= "reference/platfora_properties/platfora.builder.sample.size.html@@@platfora.builder.sample.size@@@Enter the number of rows Platfora samples from the dataset and retains for dataset profiling...";
fil["508"]= "reference/platfora_properties/platfora.catalog.cache.enabled.html@@@platfora.catalog.cache.enabled@@@Enables caching of catalog metadat...";
fil["509"]= "reference/platfora_properties/platfora.cluster.status.timeout.millis.html@@@platfora.cluster.status.timeout.millis@@@Time until an unanswered cluster node ping is considered to indicate unavailability...";
fil["510"]= "reference/platfora_properties/platfora.cors.domain.html@@@platfora.cors.domain@@@Which domains to accept requests from...";
fil["511"]= "reference/platfora_properties/platfora.cors.enabled.html@@@platfora.cors.enabled@@@Indicates if cross-domain header support is enabled...";
fil["512"]= "reference/platfora_properties/platfora.csv.download.max.rows.html@@@platfora.csv.download.max.rows@@@Sets the maximum number of lens rows for a single download operation...";
fil["513"]= "reference/platfora_properties/platfora.data.dir.html@@@platfora.data.dir@@@Local directory Platfora uses to store source from lens builds and various metadata and log files...";
fil["514"]= "reference/platfora_properties/platfora.data.download.html@@@platfora.data.download@@@Enables or disables data download of an entire lens...";
fil["515"]= "reference/platfora_properties/platfora.data.export.html@@@platfora.data.export@@@Enables or disables data export of an entire lens...";
fil["516"]= "reference/platfora_properties/platfora.dataset.data.access.enabled.html@@@platfora.dataset.data.access.enabled@@@Choose whether or not to control data access at both the data source and dataset. True (eanbled) means it is controlled at both locations, false (disabled) means it is controlled at the data source only...";
fil["517"]= "reference/platfora_properties/platfora.datasetparts.hive.limit.html@@@platfora.datasetparts.hive.limit@@@Enter the number of Hive partitions/buckets to scan when creating a new dataset. You might want to limit this number to improve performance...";
fil["518"]= "reference/platfora_properties/platfora.debug.display.lensbuild.warnings.html@@@platfora.debug.display.lensbuild.warnings@@@Choose whether or not to display lens build warnings for successful lens builds in the Platfora web application on the Data Catalog page for lenses and when selecting a lens for a vizboard...";
fil["519"]= "reference/platfora_properties/platfora.debug.failed.task.log.num.html@@@platfora.debug.failed.task.log.num@@@Enter the number of task log files from failed map and reduce job tasks for each step in a lens build to include in the Platfora server log...";
fil["520"]= "reference/platfora_properties/platfora.debug.killed.task.log.num.html@@@platfora.debug.killed.task.log.num@@@Enter the number of task log files from killed map and reduce job tasks for each step in a lens build to include in the Platfora server log...";
fil["521"]= "reference/platfora_properties/platfora.debug.mapper.task.log.num.html@@@platfora.debug.mapper.task.log.num@@@Enter the number of map task log files from successful map job tasks for each step in a lens build to include in the Platfora server log...";
fil["522"]= "reference/platfora_properties/platfora.debug.packing.size.html@@@platfora.debug.packing.size@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["523"]= "reference/platfora_properties/platfora.debug.reducer.task.log.num.html@@@platfora.debug.reducer.task.log.num@@@Enter the number of reduce task log files from successful reduce job tasks for each step in a lens build to include in the Platfora server log...";
fil["524"]= "reference/platfora_properties/platfora.dfs.datadir.html@@@platfora.dfs.datadir@@@Specify a DFS data directory where Platfora build s store its data in Hadoop...";
fil["525"]= "reference/platfora_properties/platfora.dfs.hive.libdir.html@@@platfora.dfs.hive.libdir@@@Location of the distributed file system (DFS) directory where Platfora places JAR files for Hive plugins...";
fil["526"]= "reference/platfora_properties/platfora.dfs.intermediatedir.html@@@platfora.dfs.intermediatedir@@@Specify a directory that Platfora uses to store intermediate lens build dat...";
fil["527"]= "reference/platfora_properties/platfora.dfs.jobxml.lens.limit.html@@@platfora.dfs.jobxml.lens.limit@@@Number of lenses whose JobXML files we store in the logs directory...";
fil["528"]= "reference/platfora_properties/platfora.dfs.libdir.html@@@platfora.dfs.libdir@@@Displays the Hadoop DFS directory where Platfora stores its jar files...";
fil["529"]= "reference/platfora_properties/platfora.dfscache.prune.html@@@platfora.dfscache.prune@@@Remove unknown files from the DFS cache on startup...";
fil["530"]= "reference/platfora_properties/platfora.dfscache.size.fraction.html@@@platfora.dfscache.size.fraction@@@Enter the percentage (expressed as a fraction) of the local disk that Platfora uses to store lens build data in the Fractal Cache (DFS cache...";
fil["531"]= "reference/platfora_properties/platfora.disable.temp.cleanup.html@@@platfora.disable.temp.cleanup@@@Choose whether or not Platfora should remove the temporary lens files on HDFS after a lens build completes...";
fil["532"]= "reference/platfora_properties/platfora.distributed.query.exec.thresh.html@@@platfora.distributed.query.exec.thresh@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["533"]= "reference/platfora_properties/platfora.emr.accesskey.html@@@platfora.emr.accesskey@@@Enter your AWS account access key ID...";
fil["534"]= "reference/platfora_properties/platfora.emr.ami.version.html@@@platfora.emr.ami.version@@@The EMR Amazon Machine Image (AMI) to use to initialize EC2 instances...";
fil["535"]= "reference/platfora_properties/platfora.emr.bootstrap.action.html@@@platfora.emr.bootstrap.action@@@Specify a bootstrap action to run on job flow startup...";
fil["536"]= "reference/platfora_properties/platfora.emr.ec2key.name.html@@@platfora.emr.ec2key.name@@@Name of the EC2 key pair to use for SSH access to your EMR instances...";
fil["537"]= "reference/platfora_properties/platfora.emr.endpoint.html@@@platfora.emr.endpoint@@@The Amazon EMR endpoint for your region (for example, elasticmapreduce.us-west-1.amazonaws.com...";
fil["538"]= "reference/platfora_properties/platfora.emr.hadoop.version.html@@@platfora.emr.hadoop.version@@@The Hadoop version to use for EMR...";
fil["539"]= "reference/platfora_properties/platfora.emr.instance.count.html@@@platfora.emr.instance.count@@@Number of EC2 instances to initialize for a Platfora lens build...";
fil["540"]= "reference/platfora_properties/platfora.emr.instancetype.master.html@@@platfora.emr.instancetype.master@@@Specify the EC2 instance type to initialize for the EMR Hadoop JobTracker node...";
fil["541"]= "reference/platfora_properties/platfora.emr.instancetype.slave.html@@@platfora.emr.instancetype.slave@@@Specify the EC2 instance type to initialize for the EMR Hadoop TaskTracker nodes...";
fil["542"]= "reference/platfora_properties/platfora.emr.jardir.html@@@platfora.emr.jardir@@@Enter an S3 directory where Platfora writes its jar files...";
fil["543"]= "reference/platfora_properties/platfora.emr.jobconfdir.html@@@platfora.emr.jobconfdir@@@The S3 directory location where Platfora writes its build metadata files...";
fil["544"]= "reference/platfora_properties/platfora.emr.jobflow.reuse.html@@@platfora.emr.jobflow.reuse@@@Choose whether or not to reuse existing job flows...";
fil["545"]= "reference/platfora_properties/platfora.emr.log.uri.html@@@platfora.emr.log.uri@@@Specify an S3 Native URI where EMR periodically synchronizes its job flow log files...";
fil["546"]= "reference/platfora_properties/platfora.emr.placement.html@@@platfora.emr.placement@@@The region plus availability zone code that is available for your Amazon Web Services (AWS) account (for example: us-west-2...";
fil["547"]= "reference/platfora_properties/platfora.emr.secretkey.html@@@platfora.emr.secretkey@@@Enter your AWS account secret key...";
fil["548"]= "reference/platfora_properties/platfora.emr.shutdown.runway.html@@@platfora.emr.shutdown.runway@@@When platfora.emr.jobflow.reuse is enabled (set to true), this configures the amount of time in seconds to begin terminating a job flow before the next EMR payment increment occurs...";
fil["549"]= "reference/platfora_properties/platfora.emr.shutdown.timeout.html@@@platfora.emr.shutdown.timeout@@@Job flow inactivity timeout in seconds...";
fil["550"]= "reference/platfora_properties/platfora.emr.status.timeout.html@@@platfora.emr.status.timeout@@@When platfora.emr.jobflow.reuse is enabled (set to true), this configures the time in seconds to wait for a response from the EMR job flow before terminating it...";
fil["551"]= "reference/platfora_properties/platfora.emr.termination.protected.html@@@platfora.emr.termination.protected@@@Choose whether or not EMR instances are terminated after a lens build...";
fil["552"]= "reference/platfora_properties/platfora.emr.visibility.allusers.html@@@platfora.emr.visibility.allusers@@@Choose whether or not to make the EMR job flow visible to all users...";
fil["553"]= "reference/platfora_properties/platfora.enable.temp.cache.html@@@platfora.enable.temp.cache@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["554"]= "reference/platfora_properties/platfora.field.finder.enabled.html@@@platfora.field.finder.enabled@@@Enables or disables the Field Finder feature...";
fil["555"]= "reference/platfora_properties/platfora.filesystem.browse.timeout.html@@@platfora.filesystem.browse.timeout@@@Enter the number of seconds before Platfora returns an error in the web application when trying to connect to an unresponsive data source during data ingest...";
fil["556"]= "reference/platfora_properties/platfora.footer.dismissable.html@@@platfora.footer.dismissable@@@Determines if a Platfora user can dismiss the footer s display...";
fil["557"]= "reference/platfora_properties/platfora.footer.enabled.html@@@platfora.footer.enabled@@@Enables or disable display of a custom footer message...";
fil["558"]= "reference/platfora_properties/platfora.footer.message.html@@@platfora.footer.message@@@A message to display in the application footer...";
fil["559"]= "reference/platfora_properties/platfora.header.dismissable.html@@@platfora.header.dismissable@@@Determines if a Platfora user can dismiss the header s display...";
fil["560"]= "reference/platfora_properties/platfora.header.enabled.html@@@platfora.header.enabled@@@Enables or disable display of a custom header message...";
fil["561"]= "reference/platfora_properties/platfora.header.message.html@@@platfora.header.message@@@A message to display in the application header...";
fil["562"]= "reference/platfora_properties/platfora.hive.classpath.html@@@platfora.hive.classpath@@@Displays the Hadoop DFS directory where Platfora stores its jar files...";
fil["563"]= "reference/platfora_properties/platfora.hive.direct.partitions.html@@@platfora.hive.direct.partitions@@@When Platfora uses a JDBC connection to a Hive MetaStore database, choose whether or not Platfora fetches partition information directly from the database instead of using the client API...";
fil["564"]= "reference/platfora_properties/platfora.hive.libdir.html@@@platfora.hive.libdir@@@Location of a local directory that contains Hive library JARs...";
fil["565"]= "reference/platfora_properties/platfora.hive.metastore.concurrency.html@@@platfora.hive.metastore.concurrency@@@Enter the maximum number of concurrent connections Platfora makes to the Hive metastore...";
fil["566"]= "reference/platfora_properties/platfora.home.html@@@platfora.home@@@The location on the local disk where Platfora is installed...";
fil["567"]= "reference/platfora_properties/platfora.jdbc.connection.html@@@platfora.jdbc.connection@@@JDBC connection URL for metadata catalog. JDBC connection string for the database where Platfora stores its metadata in Postgres...";
fil["568"]= "reference/platfora_properties/platfora.jdbc.connectionTimeout.html@@@platfora.jdbc.connectionTimeout@@@Maximum time in seconds an idle JDBC connection is retained before closing...";
fil["569"]= "reference/platfora_properties/platfora.jdbc.debugConnectionLeak.html@@@platfora.jdbc.debugConnectionLeak@@@Choose whether or not to capture a stacktrace in the Platfora server logs for leaked JDBC connections when the platfora.jdbc.connectionTimeout timeout is reached...";
fil["570"]= "reference/platfora_properties/platfora.jdbc.logsql.html@@@platfora.jdbc.logsql@@@Choose whether or not to enable SQL logging...";
fil["571"]= "reference/platfora_properties/platfora.jdbc.maxConnections.html@@@platfora.jdbc.maxConnections@@@Enter the maximum number of JDBC connections Platfora can make to the Metadata Catalog stored in a Postgres database...";
fil["572"]= "reference/platfora_properties/platfora.jdbc.obtainConnectionTimeout.html@@@platfora.jdbc.obtainConnectionTimeout@@@Enter the maximum time in milliseconds Platfora tries to create a JDBC connection before throwing a SQL exception...";
fil["573"]= "reference/platfora_properties/platfora.ldap.connection.timeoutmillis.html@@@platfora.ldap.connection.timeoutmillis@@@Enter the amount of time, in milliseconds, Platfora waits to make a connection with an LDAPS server before it fails the connection...";
fil["574"]= "reference/platfora_properties/platfora.ldap.response.timeoutmillis.html@@@platfora.ldap.response.timeoutmillis@@@Enter the amount of time, in milliseconds, Platfora waits for a response from an LDAPS server before closing the connection...";
fil["575"]= "reference/platfora_properties/platfora.ldap.secure.validateEnabled.html@@@platfora.ldap.secure.validateEnabled@@@Choose whether or not Platfora validates the LDAPS server secure certificate...";
fil["576"]= "reference/platfora_properties/platfora.ldap.truststore.location.html@@@platfora.ldap.truststore.location@@@Enter the location of the Java trustStore to use when connecting to a secure LDAPS server...";
fil["577"]= "reference/platfora_properties/platfora.ldap.truststore.password.html@@@platfora.ldap.truststore.password@@@Set the password in the Java trustStore for connecting to secure LDAPS servers...";
fil["578"]= "reference/platfora_properties/platfora.ldap.truststore.type.html@@@platfora.ldap.truststore.type@@@Set the type of Java trustStore for connecting to secure LDAPS servers...";
fil["579"]= "reference/platfora_properties/platfora.ldap.userImportEnabled.html@@@platfora.ldap.userImportEnabled@@@Choose whether or not to users can automatically create a Platfora user by logging into Platfora using their LDAP credentials...";
fil["580"]= "reference/platfora_properties/platfora.lens.compression.html@@@platfora.lens.compression@@@Choose whether or not Platfora compresses lens files on disk...";
fil["581"]= "reference/platfora_properties/platfora.license.expirationwarningdays.html@@@platfora.license.expirationwarningdays@@@Enter the number of days to display a warning message in the web UI before the Platfora licenses expires...";
fil["582"]= "reference/platfora_properties/platfora.lineage.max.files.display.html@@@platfora.lineage.max.files.display@@@The maximum number of source files specific to the lens build to list in a data lineage report that is displayed in the Platfora web application...";
fil["583"]= "reference/platfora_properties/platfora.lineage.max.files.total.html@@@platfora.lineage.max.files.total@@@The maximum number of source files specific to the lens build Platfora fetches from HDFS for data lineage reports...";
fil["584"]= "reference/platfora_properties/platfora.lineage.max.levels.display.html@@@platfora.lineage.max.levels.display@@@The maximum height of the tree in the data lineage report represented by the number of node levels as displayed in the Platfora web application...";
fil["585"]= "reference/platfora_properties/platfora.lineage.max.levels.total.html@@@platfora.lineage.max.levels.total@@@Enter the maximum height of the tree in the data lineage report represented by the number of node levels that Platfora fetches for data lineage reports...";
fil["586"]= "reference/platfora_properties/platfora.local.coordinator.report.progress.millis.html@@@platfora.local.coordinator.report.progress.millis@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["587"]= "reference/platfora_properties/platfora.log.gc.duration.thresh.html@@@platfora.log.gc.duration.thresh@@@Sets a threshold logging garbage collections...";
fil["588"]= "reference/platfora_properties/platfora.max.corrupt.files.to.skip.html@@@platfora.max.corrupt.files.to.skip@@@Enter the maximum number of invalid/corrupt compressed source files to skip before failing a lens build...";
fil["589"]= "reference/platfora_properties/platfora.max.fields.per.job.html@@@platfora.max.fields.per.job@@@Maximum number of fields computed per event series processing job...";
fil["590"]= "reference/platfora_properties/platfora.max.line.length.html@@@platfora.max.line.length@@@The maximum number of characters allowed for a row in a delimited text-based dataset...";
fil["591"]= "reference/platfora_properties/platfora.max.pattern.events.html@@@platfora.max.pattern.events@@@Maximum number of events considered for a single partition in a pattern match expression...";
fil["592"]= "reference/platfora_properties/platfora.max.worker.threads.html@@@platfora.max.worker.threads@@@Maximum number of worker threads to use for query processing...";
fil["593"]= "reference/platfora_properties/platfora.multinode.nodeId.html@@@platfora.multinode.nodeId@@@ID number of the current Platfora node...";
fil["594"]= "reference/platfora_properties/platfora.num.errors.reported.html@@@platfora.num.errors.reported@@@Enter the maximum number of MapReduce task errors, such as skipped source rows, to log in the task log when building a lens...";
fil["595"]= "reference/platfora_properties/platfora.num.local.dfscache.prefetchers.html@@@platfora.num.local.dfscache.prefetchers@@@Enter the number of threads Platfora uses to copy lens files from HDFS to the Platfora cluster...";
fil["596"]= "reference/platfora_properties/platfora.pool.array.fraction.html@@@platfora.pool.array.fraction@@@Percentage of available Java heap space consumed by currently unused temporary arrays...";
fil["597"]= "reference/platfora_properties/platfora.pool.columnbuffer.fraction.html@@@platfora.pool.columnbuffer.fraction@@@Percentage of the total Java heap space to use for caching lens data in memory...";
fil["598"]= "reference/platfora_properties/platfora.pool.query.agg.memory.fraction.html@@@platfora.pool.query.agg.memory.fraction@@@Fraction of memory used for aggregation operation...";
fil["599"]= "reference/platfora_properties/platfora.query.always.sort.html@@@platfora.query.always.sort@@@Enables or disables query sorting...";
fil["600"]= "reference/platfora_properties/platfora.query.assign.primary.workunits.threshold.html@@@platfora.query.assign.primary.workunits.threshold@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["601"]= "reference/platfora_properties/platfora.query.logging.block.rows.html@@@platfora.query.logging.block.rows@@@Enter the number of rows of intermediate query results to write to the Platfora server logs in debug mode. For Platfora internal use only...";
fil["602"]= "reference/platfora_properties/platfora.query.parallelize.limit.html@@@platfora.query.parallelize.limit@@@Enables or disable parallelize limit during query processing...";
fil["603"]= "reference/platfora_properties/platfora.query.plan.runner.init.timeout.millis.html@@@platfora.query.plan.runner.init.timeout.millis@@@Enter the amount of time in milliseconds a query has to initialize before aborting the query...";
fil["604"]= "reference/platfora_properties/platfora.query.plan.runner.timeout.millis.html@@@platfora.query.plan.runner.timeout.millis@@@Enter the time in milliseconds the query processor should wait before timing out...";
fil["605"]= "reference/platfora_properties/platfora.query.starjoin.html@@@platfora.query.starjoin@@@Controls which query engine your installation uses...";
fil["606"]= "reference/platfora_properties/platfora.query.timeout.millis.html@@@platfora.query.timeout.millis@@@Enter the amount of time in milliseconds a query is unresponsive before aborting the query...";
fil["607"]= "reference/platfora_properties/platfora.query.use.master.html@@@platfora.query.use.master@@@Choose whether or not some query tasks should only run worker nodes, or on worker nodes and the master node...";
fil["608"]= "reference/platfora_properties/platfora.query.workunits.pct.per.request.html@@@platfora.query.workunits.pct.per.request@@@This is used to finetune the queries. Only change when instructed by Platfora engineering or Customer Support...";
fil["609"]= "reference/platfora_properties/platfora.querynodes.per.block.html@@@platfora.querynodes.per.block@@@Replication factor for lens dat...";
fil["610"]= "reference/platfora_properties/platfora.rawdataset.cacheenabled.html@@@platfora.rawdataset.cacheenabled@@@Choose whether or not to enable the dataset cache...";
fil["611"]= "reference/platfora_properties/platfora.rawdataset.cacheentryblocksizekb.html@@@platfora.rawdataset.cacheentryblocksizekb@@@The block size in KB of each entry in the dataset cache...";
fil["612"]= "reference/platfora_properties/platfora.rawdataset.cacheentrynumlimit.html@@@platfora.rawdataset.cacheentrynumlimit@@@Enter the maximum number of total entries (source files) Platfora stores in the dataset cache...";
fil["613"]= "reference/platfora_properties/platfora.rawdataset.cacheexpirehours.html@@@platfora.rawdataset.cacheexpirehours@@@Enter the number of hours an entry (source file) is kept in the dataset cache before it expires...";
fil["614"]= "reference/platfora_properties/platfora.rawdataset.cachesizemb.html@@@platfora.rawdataset.cachesizemb@@@Enter the maximum size in MB Platfora uses to store an entry (source file) in the dataset cache...";
fil["615"]= "reference/platfora_properties/platfora.rawdataset.cachetimeoutminutes.html@@@platfora.rawdataset.cachetimeoutminutes@@@Enter the maximum time in minutes to allow for downloading remote source data during data ingest (which will be loaded into the dataset cache as a cache entry) before timing out...";
fil["616"]= "reference/platfora_properties/platfora.reduce.tasks.html@@@platfora.reduce.tasks@@@Enter the maximum number of Hadoop reduce tasks Platfora uses for MapReduce jobs...";
fil["617"]= "reference/platfora_properties/platfora.rendering.enabled.html@@@platfora.rendering.enabled@@@Allow vizboard-to-PDF rendering...";
fil["618"]= "reference/platfora_properties/platfora.rendering.job.artifact.maxAge.html@@@platfora.rendering.job.artifact.maxAge@@@Number of days to retain job artifacts...";
fil["619"]= "reference/platfora_properties/platfora.rendering.job.timeout.html@@@platfora.rendering.job.timeout@@@Timeout (in seconds) for long-running jobs...";
fil["620"]= "reference/platfora_properties/platfora.rendering.maxJobs.html@@@platfora.rendering.maxJobs@@@Maximum number of parallel rendering jobs...";
fil["621"]= "reference/platfora_properties/platfora.requestcache.cachesize.html@@@platfora.requestcache.cachesize@@@Define the maximum size of the HTTP request cache in bytes...";
fil["622"]= "reference/platfora_properties/platfora.requestcache.objectsize.html@@@platfora.requestcache.objectsize@@@Enter the maximum object size in bytes for objects stored in the HTTP request cache...";
fil["623"]= "reference/platfora_properties/platfora.s3.endpoint.html@@@platfora.s3.endpoint@@@The endpoint Platfora uses to access S3 buckets...";
fil["624"]= "reference/platfora_properties/platfora.s3.filesystem.optimization.enable.html@@@platfora.s3.filesystem.optimization.enable@@@Choose whether or not to enable Platfora s optimized S3 access library...";
fil["625"]= "reference/platfora_properties/platfora.server.management.port.html@@@platfora.server.management.port@@@The port over which the Platfora server and worker nodes communicate with each other...";
fil["626"]= "reference/platfora_properties/platfora.ssl.enabled.html@@@platfora.ssl.enabled@@@Choose whether or not to allow secure connections to Platfora using HTTPS...";
fil["627"]= "reference/platfora_properties/platfora.ssl.keystore.location.html@@@platfora.ssl.keystore.location@@@Enter the location of the Java keyStore to use for SSL connections...";
fil["628"]= "reference/platfora_properties/platfora.ssl.keystore.password.html@@@platfora.ssl.keystore.password@@@Set the password in the Java keyStore to use for SSL connections...";
fil["629"]= "reference/platfora_properties/platfora.ssl.keystore.type.html@@@platfora.ssl.keystore.type@@@Set the type of Java keyStore to use for SSL connections...";
fil["630"]= "reference/platfora_properties/platfora.ssl.port.html@@@platfora.ssl.port@@@Enter a port number to use for secure connections using SSL when secure connections is enabled...";
fil["631"]= "reference/platfora_properties/platfora.ssl.truststore.location.html@@@platfora.ssl.truststore.location@@@Enter the location of the Java trustStore to use for SSL connections...";
fil["632"]= "reference/platfora_properties/platfora.ssl.truststore.password.html@@@platfora.ssl.truststore.password@@@Set the password in the Java trustStore to use for SSL connections...";
fil["633"]= "reference/platfora_properties/platfora.ssl.truststore.type.html@@@platfora.ssl.truststore.type@@@Set the type of Java trustStore to use for SSL connections...";
fil["634"]= "reference/platfora_properties/platfora.support.identifier.html@@@platfora.support.identifier@@@Enter an identifier, such as your organization name, that will be used in syscapture file names...";
fil["635"]= "reference/platfora_properties/platfora.telemetry.aggregate.frequency.html@@@platfora.telemetry.aggregate.frequency@@@Enter how often to aggregate telemetry data, in seconds...";
fil["636"]= "reference/platfora_properties/platfora.telemetry.enabled.html@@@platfora.telemetry.enabled@@@Choose whether or not to send system metrics data from the Platfora server to Platfora using HTTPS to improve user experience and performance...";
fil["637"]= "reference/platfora_properties/platfora.telemetry.file.lifespan.html@@@platfora.telemetry.file.lifespan@@@Enter how long each telemetry file lives on the Platfora master server in seconds...";
fil["638"]= "reference/platfora_properties/platfora.telemetry.logparser.enabled.html@@@platfora.telemetry.logparser.enabled@@@Choose whether or not to include internal Platfora errors with telemetry to help Platfora improve product quality...";
fil["639"]= "reference/platfora_properties/platfora.telemetry.send.frequency.html@@@platfora.telemetry.send.frequency@@@Enter how often the Platfora master server sends telemetry data to Platfora, in seconds...";
fil["640"]= "reference/platfora_properties/platfora.telemetry.url.html@@@platfora.telemetry.url@@@Enter the URL to where the Platfora server sends the telemetry dat...";
fil["641"]= "reference/platfora_properties/platfora.udf.class.names.html@@@platfora.udf.class.names@@@Enter a comma-separated list of Java class names for implementing any user defined functions (UDFs...";
fil["642"]= "reference/platfora_properties/platfora.unicode.escaping.json.html@@@platfora.unicode.escaping.json@@@Choose whether or not to escape Unicode characters in data values when generating visualizations...";
fil["643"]= "reference/platfora_properties/platfora.unique.query.ids.html@@@platfora.unique.query.ids@@@Choose whether or not to generate query IDs that are unique across restarts...";
fil["644"]= "reference/platfora_properties/platfora.usermanagement.cache.expireHours.html@@@platfora.usermanagement.cache.expireHours@@@Enter how much time, in hours, user or group information exists in the user management cache since its creation before being deleted...";
fil["645"]= "reference/platfora_properties/platfora.viz.max.rows.html@@@platfora.viz.max.rows@@@Maximum number of result records (rows) to return for a visualization...";
fil["646"]= "reference/platfora_properties/platfora.web.api.exception.included.html@@@platfora.web.api.exception.included@@@When enabled, any REST API call that results in an exception in Platfora includes the error stack trace in the body of the HTTP response...";
fil["647"]= "reference/platfora_properties/platfora.webservice.port.html@@@platfora.webservice.port@@@The port used to access the Platfora GUI with a web browser using HTTP...";
fil["648"]= "reference/platfora_properties/platfora.workunit.size.html@@@platfora.workunit.size@@@Number of blocks in each workunit assignment for the Query Processor...";
fil["649"]= "reference/platfora_properties/property_reference_top.html@@@Platfora Configuration Property Reference@@@Platfora is highly configurable, providing many different properties you can use to fine tune how it performs. You can configure preferences, such as whether or not to compress lenses, and improve performance in your environment based on assistance and feedback from customer support...";
fil["650"]= "reference/platfora_properties/security_properties_top.html@@@Security Properties@@@The security properties allow you to configure some of the various security features Platfora provides, including authentication and SSL access...";
fil["651"]= "reference/platfora_properties/versioninfo_properties_top.html@@@Version Information Properties@@@The version information properties display information about the current installation of Platfora as determined during installation or upgrade...";
fil["652"]= "reference/regular_expressions/regex_boundaries.html@@@Regex Line and Word Boundaries@@@Boundary matching constructs are used to specify where in a string to apply a matching pattern. For example, you can search for a particular pattern within a word boundary, or search for a pattern at the beginning or end of a line...";
fil["653"]= "reference/regular_expressions/regex_character_classes.html@@@Regex Character Classes@@@A character class allows you to specify a set of characters, enclosed in square brackets, that can produce a single character match. There are also a number of special predefined character classes (backslash character sequences that are shorthand for the most common character sets...";
fil["654"]= "reference/regular_expressions/regex_groups.html@@@Regex Capturing Groups@@@Groups are specified by a pair of parenthesis around a subpattern in the regular expression. By placing part of a regular expression inside parentheses, you group that part of the regular expression together. This allows you to apply regex operators and quantifiers to the entire group at once. Besides grouping part of a regular expression together, parenthesis also create a capturing group. Capturing groups are used to determine which matching values to save or return from your regular expression...";
fil["655"]= "reference/regular_expressions/regex_metacharacters.html@@@Regex Literal and Special Characters@@@The most basic form of regular expression pattern matching is the match of a literal character or string. Regular expressions also have a number of special characters that affect the way a pattern is matched. This section describes the regular expression syntax for referring to literal characters, special characters, non-printable characters (such as a tab or a newline), and special character escaping...";
fil["656"]= "reference/regular_expressions/regex_quantifiers.html@@@Regex Quantifiers@@@Quantifiers specify how often the preceding regular expression construct should match. There are three classes of quantifiers: greedy, reluctant, and possessive. The difference between greedy, reluctant, and possessive quantifiers involves what part of the string to try for the initial match, and how to retry if the initial attempt does not produce a match...";
fil["657"]= "reference/regular_expressions/regex_ref_top.html@@@Regular Expression Reference@@@Regular expressions, also referred to as regex or regexp, are a standardized collection of special characters and constructs used for matching strings of text. They provide a flexible and precise language for matching particular characters, words, or patterns of characters. Regular expressions vary in complexity using a combination of basic constructs to describe a string matching pattern. This reference describes the most common regular expression matching patterns, but is not a comprehensive list...";
fil["658"]= "reference/sql/define_clause.html@@@DEFINE Clause@@@Defines a computed field to include in a SELECT statement...";
fil["659"]= "reference/sql/group_by_clause.html@@@GROUP BY Clause@@@Orders and optionally limit the results of a SELECT statement...";
fil["660"]= "reference/sql/having_clause.html@@@HAVING Clause@@@Filters a SELECT statement by a measure expression...";
fil["661"]= "reference/sql/select_statement.html@@@SELECT Statement@@@Queries an aggregate lens. A SELECT statement is input to a progammatic lens query...";
fil["662"]= "reference/sql/sql_examples.html@@@Example of Lens Queries@@@This section provides some tips and examples for querying a lens...";
fil["663"]= "reference/sql/where_clause.html@@@WHERE Clause@@@Filters a lens query by one or more predicate expression...";
fil["664"]= "system/configure_email_server.html@@@Configure Platfora to Send Email@@@To enable Platfora to send email messages, you must configure Platfora to connect as a client to an outgoing email server that uses SMTP (Simple Mail Transfer Protocol...";
fil["665"]= "system/system_admin_top.html@@@System Administration@@@From the Platfora System page, authorized system administrators can manage and monitor various aspects of the Platfora system, such as lens builds, user access, data access, server resources, and system configuration. Users who do not have system administrator permissions will only have access to the System page to monitor and manage their own lenses...";
fil["666"]= "system/install_planning/install_plan_intro.html@@@Understand the Platfora Installation@@@This section describes the Platfora installation. You ll learn about the hardware and software requirements for a Platfora master and/or server node. You ll also learn about the supported Hadoop implementations and what is required of them. Finally, you ll learn about the components of a Platfora installation. If you want to install the Platfora software, refer to the appropriate Platfora install guide for your Hadoop implementation...";
fil["667"]= "system/install_planning/installed_dirs.html@@@Installation Variables and Directories@@@This section describes the directories, important files, and environment variables in a Platfora installation...";
fil["668"]= "system/lens_management/about_lens_sizes.html@@@Understand Lens Disk Usage@@@The amount of space a lens uses on HDFS and the Platfora local disk depends on whether or not it shares data with another lens. When possible, Platfora shares lens files between lenses when those lenses share data. This allows Platfora to save disk space both on HDFS and Platfor...";
fil["669"]= "system/lens_management/avoid_killed_tasks.html@@@Avoid Killed Tasks by the CapacityScheduler@@@If your Hadoop distribution is using the CapacityScheduler, your lens builds can exceed the scheduler limits...";
fil["670"]= "system/lens_management/avoid_mr_errors.html@@@Avoid MapReduce Out-of-Memory Errors@@@Better tuning of the TaskTracker task properties and Java virtual memory (JVM) settings can fix these errors...";
fil["671"]= "system/lens_management/capture_hadoop_logs.html@@@Capture Hadoop Logs for Failed Lens Builds@@@System administrators can configure the amount of diagnostic data Platfora server logs include from the Hadoop TaskTracker logs. You might want to increase the amount of diagnostic data when troubleshooting lens build failures...";
fil["672"]= "system/lens_management/determine_lens_size_HDFS.html@@@Determine Lens Size on HDFS@@@The amount of space a lens uses on HDFS depends on whether or not it shares data with another lens. The System &gt; Activities & Lenses page displays the total lens size including any files shared with other lenses...";
fil["673"]= "system/lens_management/determine_lens_size_Platfora.html@@@Determine Lens Size on Platfora@@@The amount of space a lens uses on the Platfora local disk depends on whether or not it shares data with another lens. The System &gt; Resources page displays the size of the lens files stored on the Platfora local disk that are unique to each lens. The lens size does not include files shared with other lenses. Complete these steps to view view how much space will become available on Platfora when you unbuild or delete a lens...";
fil["674"]= "system/lens_management/ensure_final_parameters.html@@@Check for Final Hadoop Parameters@@@Hadoop may ignore your Platfora-generated job parameters causing your lens builds to fail...";
fil["675"]= "system/lens_management/find_lens_build_failures.html@@@Where to Look When a Lens Build Fails@@@Troubleshooting a lens build failure is an iterative process. Start by looking in Platfora for information, and then moving to Hadoop for additional information if necessary...";
fil["676"]= "system/lens_management/lens_build_failure_reasons.html@@@Common Reasons Lens Jobs Fail@@@Lens jobs might fail due to a problem with Hadoop, Platfora, or the input dat...";
fil["677"]= "system/lens_management/lens_warning_duplicate_pks.html@@@Duplicate Primary Keys@@@A Duplicate Primary Keys warning only occurs when building a lens from a dataset that references other datasets. This means that a referenced dataset had duplicate primary key values, and those duplicate rows were dropped before joining to the fact dataset...";
fil["678"]= "system/lens_management/lens_warning_empty_lens.html@@@Lens Contains No Rows@@@A Lens Contains No Rows warning means that the lens build succeeded, but the resulting lens contains no data. This can happen when lens filters are too exclusive, or if the source data files themselves are empty or corrupt...";
fil["679"]= "system/lens_management/lens_warning_esp_limit.html@@@Max Pattern Events Exceeded@@@The Max Pattern Events Exceeded warning only occurs for lenses that contain an event series processing computed field (a field defined with a PARTITION expression). This means that some rows were not processed during event series processing, and those computed fields may have incorrect results...";
fil["680"]= "system/lens_management/lens_warning_skip_files.html@@@Skipped Files@@@A Skipped Files warning means that some source data files were skipped during lens build processing, and the lens may not contain all of the data you were expecting...";
fil["681"]= "system/lens_management/lens_warning_unjoined_fks.html@@@Unjoined and NULL Foreign Keys@@@Unjoined Foreign Keys or NULL Foreign Keys warnings only occur when building a lens from a dataset that references other datasets. This means that the foreign key column(s) of the fact dataset contains key values that cannot be found in the referenced dataset...";
fil["682"]= "system/lens_management/lens_warnings.html@@@Investigate Lens Data Quality Warnings@@@This section describes the types of lens data quality warnings that Platfora reports and how to handle them...";
fil["683"]= "system/lens_management/manage_lenses.html@@@Manage Lenses@@@The Activities & Lenses tab of the System page has a Lenses section where you can Update (refresh the lens data in Platfora), Delete (remove the lens data structures and lens definition) or Unbuild (keep the lens definition but remove the lens data structures) lenses...";
fil["684"]= "system/lens_management/mapred_troubleshoot.html@@@Troubleshoot Hadoop Configuration Problems@@@This section describes how to adjust certain Hadoop-controlled parameters to avoid some common MapReduce errors in Platfora lens builds...";
fil["685"]= "system/lens_management/monitor_lens_jobs.html@@@Monitor Lens Build Jobs@@@Depending on the size of the source data requested, it may take a while to process the requested data in Hadoop to build a Platfora lens. The lens is not available for use in visualizations until the lens build is complete. You can check the status of a lens build on the System page...";
fil["686"]= "system/lens_management/s3_hdfs_config.html@@@Avoiding Dictionary Errors in Lens Builds@@@This section describes how to configure Platfora to avoid dictionary errors resulting from modifications to HDFS and S3 data sources...";
fil["687"]= "system/lens_management/system_lens_top.html@@@Manage Lens Builds and Lenses@@@The Activities & Lenses tab of the System page is where you can manage all lenses in Platfora and monitor the status of lens builds. System administrators can manage all lenses in the system. Other roles can only manage lenses they own...";
fil["688"]= "system/lens_management/troubleshoot_lens_builds_top.html@@@Troubleshoot Lens Build Failures@@@This section describes how to investigate problems when a lens build fails...";
fil["689"]= "system/license/about_license_states.html@@@View License States@@@Platfora requires a valid license for users to perform any kind of action. Platfora may be in a different state depending on the current status of the license...";
fil["690"]= "system/license/about_licenses.html@@@Understand Licensing@@@Platfora requires a valid license for users to perform any kind of action, such as creating datasets, editing users, and building lenses. A system administrator uploads a valid license key in the web UI to enable Platfora s functionality...";
fil["691"]= "system/license/add_license.html@@@Add a License Key@@@When the Platfora software is in an unlicensed state, a system administrator must upload a valid license key to activate the product functionality...";
fil["692"]= "system/license/licenses_top.html@@@Manage the Platfora License@@@The License tab of the System page is where system administrators can manage the software license installed on Platfor...";
fil["693"]= "system/license/update_license.html@@@Update a License Key@@@System administrators can update the license by uploading a different license key than the current license key. You might want to do this when the Platfora software is in an expired licensed state or when you received a new license key after purchasing additional nodes. Updating the license with a new license key completely overwrites the existing license...";
fil["694"]= "system/plugins/about_data_connectors.html@@@About Custom Data Connector Plugins@@@Platfora natively supports connecting to data sources such as Hive, HDFS, and Amazon S3. For data sources that Platfora does not support out-of-the-box, you can write your own Data Connector plugin using Platfora-provided Java interfaces. Once a custom Data Connector is installed in Platfora, users can use the custom source type to define new data sources in Platfor...";
fil["695"]= "system/plugins/install_plugin.html@@@Install a Plugin@@@You can extend Platfora functionality by installing a plugin. Once you install a plugin, you cannot remove it...";
fil["696"]= "system/plugins/plugins_top.html@@@Manage Plugins@@@The Plugins tab of the System page is where system administrators can install third-party plugins to extend Platfora functionality, such as with custom Data Connectors...";
fil["697"]= "system/resources/customize_headerfooter.html@@@Customize the Application Header and Footer@@@You can add a header and footer to the Platfora application. This feature is useful if you want to display a system-wide message such as an outage announcement...";
fil["698"]= "system/resources/monitor_performance.html@@@Monitor Viz Query Performance@@@If visualization response time declines, checking the Cache Utilization and Query Performance charts can help determine system usage...";
fil["699"]= "system/resources/other_topics_top.html@@@Other Management Topics@@@The Resources tab of the System page is where system administrators can monitor resources such as Platfora server memory, disk utilization, and status...";
fil["700"]= "system/resources/pdf_rendering.html@@@Managing PDF Rendering@@@Platfora users can render a vizboard to PDF. Then, users can download and email the PDF as needed. This section describes how to manage vizboard-to-PDF rendering in the Platfora system...";
fil["701"]= "system/resources/send_diagnostics.html@@@Capture and Send System Diagnostics@@@Diagnostics contain information that the Platfora Support team finds crucial to troubleshooting support issues. To send diagnostics, your Platfora instance must have set platfora.telementry.enabled to true. Administrators can send system diagnostics from the Platfora UI or from a Platfora master s command line...";
fil["702"]= "system/resources/system_resources_top.html@@@Monitoring the Platfora System@@@The Performance section of the Resources tab is where administrators can monitor how Platfora is serving lens query requests. You can use the log files to monitor other activities releated to your Platfora installation...";
fil["703"]= "system/resources/usage_logs.html@@@Using the Platfora Logs@@@You can review activity on the Platfora system using the logs in the $PLATFORA_DATA_DIR/logs directory. This directory exists on every master and worker node...";
fil["704"]= "system/resources/use_logs.html@@@Analyze System Activity with the Audit Log@@@Analyze Activity Using a Log You can use the platfora-access-audit.log to locate periods of high activity and highly accessed data in your system. This log files contains the following fields...";
fil["705"]= "system/security/3prong_security_model.html@@@The Three-pronged Approach@@@Platfora’s security model relies on a three-pronged permission scheme: System Role Permissions determine what actions a user is allowed to perform in the Platfora application. Object Access...";
fil["706"]= "system/security/about_data_access.html@@@Understand Data Access Permissions@@@Data access is a binary control in Platfora. A user is either authorized to see the data or they are not. Once a user has data access, they will be able to see the data inside any object (dataset, lens, or vizboard) to which they also have object access permissions...";
fil["707"]= "system/security/about_default_accounts.html@@@About the Default User and Group Accounts@@@Platfora is installed with a default system administrator account used to log in to Platfora for the first time. Every user account is automatically added to the default Everyone group...";
fil["708"]= "system/security/about_hdfs_delegated_auth.html@@@Understand HDFS Delegated Authorization@@@System administrators can configure Platfora so that it grants data access permissions to LDAP users based on the users  file permissions in HDFS. By default, users have access to data in a source by a system administrator granting them data access to a configured data source or dataset. However, to base all data access permissions on HDFS file permissions, enable the HDFS Delegated Authorization feature...";
fil["709"]= "system/security/about_object_permissions.html@@@Understand Object Permissions@@@Object access permissions control what users can do with a Platfora object (a data source, dataset, lens, or vizboard). Object access and data access are completely independent of each other in Platfora. A user must be granted access to both in order to work with an object and the data it contains...";
fil["710"]= "system/security/about_security_model.html@@@Manage Access and Permissions@@@Platfora provides role-based access control (RBAC) to configure what users can do in the Platfora application, what data they can see, and what objects they can access. Access can be controlled at both broad and detail levels...";
fil["711"]= "system/security/about_super_admin_mode.html@@@About Super Administrator Mode@@@System administrators with the appropriate permission can temporarily enter a mode where they can perform all tasks in Platfora regardless of the object and data access permissions granted to them on different objects. To do this, system administrators must enter Super Administrator mode...";
fil["712"]= "system/security/about_system_roles.html@@@Understand Platfora System Roles@@@Platfora currently has five system roles that can be assigned to a user (or group). These roles control the actions that users can do in the Platfora application. In addition to these roles, Platfora includes a Super Admin mode that allows system administrators to perform all actions...";
fil["713"]= "system/security/add_group_ldap.html@@@Mapping LDAP Groups into Platfora@@@You can add an LDAP group to Platfora by mapping in its distinguished name. LDAP users that are members of the group will then be able to access Platfora. When an LDAP user logs in to Platfora, they are automatically mapped into Platfora as long as they have group access...";
fil["714"]= "system/security/add_group_local.html@@@Adding a Group@@@Groups allow you to organize users by their functional or organizational role in order to centralize the management of permissions...";
fil["715"]= "system/security/add_user_ldap.html@@@Mapping LDAP Users into Platfora@@@There are two ways to map an LDAP user into Platfora. One way is to map an LDAP group that the user is a member of. The other way is to map an individual LDAP user into Platfor...";
fil["716"]= "system/security/add_user_local.html@@@Adding a Local User Account@@@Adding a local user gives a person access to Platfora, and creates an account for them in the Platfora application. A user s system role controls what the user can do in the Platfora application...";
fil["717"]= "system/security/allow_super_admin_mode.html@@@Allowing System Administrators to Enter Super Administrator Mode@@@Before system administrators can enter Super Administrator mode, they must be granted the ability to do so...";
fil["718"]= "system/security/configure_data_access_enforcement.html@@@Configure Data Access Enforcement@@@Users with the System Administrator role can configure the level at which Platfora allows data access permissions to be set, either the data source only or both the data source and dataset level (for more fine-grained data access control). Changing this system setting requires a restart of Platfora to take effect...";
fil["719"]= "system/security/configure_kerberos_impersonation.html@@@Configure Kerberos to Allow Impersonation@@@To use HDFS Delegated Authorization, Kerberos must be configured to allow Platfora to impersonate its LDAP users...";
fil["720"]= "system/security/configure_ldap_auth.html@@@Configure LDAP User Authentication@@@Platfora can be configured to use an external LDAP directory service to authenticate users. With LDAP enabled, users log in to Platfora using their familiar LDAP identity and credentials...";
fil["721"]= "system/security/configure_local_auth.html@@@Configure Local User Authentication@@@Local users authenticate to Platfora using a Platfora username and password. To configure local authentication, you must create a user account within Platfora for each user who needs access to the system. Once you have created user accounts, you can organize users into groups to facilitate the management of data and object access permissions...";
fil["722"]= "system/security/connect_to_ldap.html@@@Configuring LDAP Access@@@You can configure Platfora to access an external LDAP directory server to authenticate users. Platfora currently supports authenticating users in Microsoft Active Directory only...";
fil["723"]= "system/security/delete_user_local.html@@@Deleting a User@@@You cannot currently delete a user account in Platfora. You can disable a user account, however, which prevents the user from logging in to Platfor...";
fil["724"]= "system/security/disable_hdfs_delegated_auth.html@@@Disable HDFS Delegated Authorization@@@Only system administrators can disable HDFS Delegated Authorization. When HDFS Delegated Authorization is disabled after being enabled, Platfora retains the data access permissions that were assigned to all objects before the feature is disabled...";
fil["725"]= "system/security/enable_hdfs_delegated_auth.html@@@Enable HDFS Delegated Authorization@@@Only system administrators can enable HDFS Delegated Authorization. When HDFS Delegated Authorization is enabled, any previously configured data access permissions are overwritten with the permissions defined in HDFS...";
fil["726"]= "system/security/enter_super_admin_mode.html@@@Entering Super Administrator Mode@@@System Administrators who have been granted the ability to perform Super Administrator tasks can enter Super Administrator mode...";
fil["727"]= "system/security/hdfs_delegated_auth_required_perms.html@@@Required HDFS File Permissions@@@To be granted data access permission on a data source or dataset when HDFS Delegated Administration is enabled, users must have the proper HDFS file permission. This section describes those required permissions...";
fil["728"]= "system/security/hdfs_delegated_auth_requirements.html@@@HDFS Delegated Authorization Requirements@@@Platfora requires different configurations to be made before using the HDFS Delegated Authorization feature...";
fil["729"]= "system/security/how_data_access_enforcement_works.html@@@How Data Access Enforcement Works@@@Users with the System Administrator role can configure the level at which Platfora allows data access permissions to be set...";
fil["730"]= "system/security/how_hdfs_delegated_auth_works.html@@@How HDFS Delegated Authorization Works@@@However, when HDFS Delegated Authorization is enabled, Platfora authorizes itself against the Kerberos server and obtains its own Kerberos Ticket-Granting Ticket (TGT). Platfora uses the TGT to impersonate LDAP users (using Kerberos Impersonation) when communicating with HDFS and MapReduce...";
fil["731"]= "system/security/leave_super_admin_mode.html@@@Leaving Super Administrator Mode@@@System Administrators in Super Administrator mode can return to their System Administrator role...";
fil["732"]= "system/security/manage_data_access_top.html@@@Configure Data Access@@@Data access grants the ability to view data exposed by a data source. Users must have data access to a source in order to use datasets, lenses, or vizboards that use data from the source. Users have access to data in a source by being granted data access to a configured data source or dataset. Platfora can be configured to enforce data access permissions at different levels...";
fil["733"]= "system/security/manage_users_groups.html@@@Authenticate and Authorize Users@@@A user must have a login account in order to access the Platfora application. Platfora can authenticate a user s identity locally or via LDAP. Users can then be organized into groups to simplify the management of system, data, and object access permissions. Only Platfora system administrators can manage users and groups...";
fil["734"]= "system/security/set_data_access_permissions_top.html@@@Grant Data Access Permissions@@@Users must have data access granted on a data source in order to use the datasets, lenses, or vizboards derived from that source. By default, data access is controlled at the data source level. This means that users who have access to the data source can see the data in any dataset, lens or vizboard that comes from that source. Optionally, you can configure data access control at the dataset level as well...";
fil["735"]= "system/security/updating_permissions_from_hdfs.html@@@Refresh Data Access Permissions from HDFS@@@Platfora refreshes the data access permissions based on the current HDFS file permissions at midnight every day and when Platfora restarts. Midnight is determined by the configured time zone for the Platfora master node. System administrators can choose to refresh the data access permissions manually at other times...";
fil["736"]= "system/security/who_can_configure_data_access.html@@@Who Can Configure Data Access Permissions@@@Users with the proper permissions can control which users have data access to data sources and datasets...";
fil["737"]= "tutorial/about_sample_data.html@@@About the Tutorial Sample Data@@@Your Platfora installation comes with some sample data that you can use to complete this tutorial. The sample data is FAA flight data from October 2012 (the month of hurricane Sandy). There is a command-line utility in your Platfora server installation to load this data. This utility uploads five csv-formatted source files to the default Uploads data source. The sample data is about 54 MB in size...";
fil["738"]= "tutorial/add_tutorial_dataset.html@@@Add a Dataset@@@Platfora datasets define how to parse, cleanse, transform, and process Hadoop source data. The sample flights data comes with four predefined datasets: Flights, Monthly Carrier Activity, Airports, and Airline Carriers. You can examine these datasets to see different examples of computed fields, measures, and references. In this exercise, you will add an additional dataset for Planes...";
fil["739"]= "tutorial/add_tutorial_user.html@@@Create a User Account@@@Before you begin working in Platfora, it is best practice to create your own user account and log in as yourself instead of using the default administrator user account. In this exercise, we will add a new user account, grant permissions to this new user, log in as the newly created user, and set your user profile picture...";
fil["740"]= "tutorial/build_tutorial_viz_top.html@@@Build Ad Hoc Visualizations@@@Using the October 2012 Flight Data lens, you can visually analyze and explore the flights data by building visualizations (viz for short). In Platfora, visualizations are created and managed within a special project document called a vizboard. In this exercise, we will create three common types of viz charts in the Flights Tutorial vizboard: a bar chart, a scatterplot, and a heatmap...";
fil["741"]= "tutorial/create_tutorial_barchart.html@@@Build a Bar Chart Viz@@@A bar chart is used to compare a quantitative value (measure) across one or more categorical dimensions. You can show cumulative dimension values within a single bar by adding an additional dimension to the Color drop-zone. In this exercise, we will build a bar chart using the sample data in the October 2012 Flight Data lens, that compares the number of cancelled flights to non-cancelled flights on the dates surrounding Hurricane Sandy...";
fil["742"]= "tutorial/create_tutorial_heatmap.html@@@Build a Heatmap Viz@@@Heatmaps are used to compare a measure across multiple dimensions using color to show variations in the data. In this exercise we will build a heatmap to compare the busiest departure and arrival airports in terms of number of flights using the sample data in the October 2012 Flight Data lens...";
fil["743"]= "tutorial/create_tutorial_scatterplot.html@@@Build a Scatterplot Viz@@@Scatterplots are used to show the correlation of two measures over a common dimension. In this exercise, you will build a scatterplot using the sample data in the October 2012 Flight Data lens, that looks at the correlation of flight departure delays to flight arrival delays on the days surrounding Hurricane Sandy...";
fil["744"]= "tutorial/create_tutorial_segment.html@@@Add a Segment@@@You can supplement the data in a lens by creating or importing segments into the lens. A segment is a special type of dimension field that you can create to group together members of a population that meet some defined common criteria. A segment is created from a referenced dataset in a lens (such as carriers) that have some behavioral characteristic in common (such as being on time...";
fil["745"]= "tutorial/create_tutorial_vizboard.html@@@Create a Vizboard@@@A vizboard is the starting point for a data analysis activity, and can be thought of as a project workspace. Visualizations are always created and managed in the context of a vizboard. For this exercise, you will create a new vizboard named Flights Tutorial. You will create and manage all of your tutorial visualizations within this vizboard...";
fil["746"]= "tutorial/edit_tutorial_lens.html@@@Edit and Rebuild a Lens@@@The sample flights data comes with one predefined aggregate lens, October 2012 Flight Data, which has a selection of measure and dimension fields chosen from the perspective of the Flights dataset. In this exercise, we will edit the October 2012 Flight Data lens definition, change some of its field selections, add a lens filter, and then rebuild the lens to get the newly requested data from Hadoop...";
fil["747"]= "tutorial/enhance_tutorial_lens_data.html@@@Supplement Data in the Lens@@@There may be times when you need to modify, supplement, or enhance the data in a lens in order to answer a particular question or perform a certain kind of analysis. Using the data available in the October 2012 Flight Data lens, we will segment, combine, and manipulate the data to achieve the results we want...";
fil["748"]= "tutorial/load_tutorial_data.html@@@Load the Tutorial Data@@@Platfora installs with some sample data that you can load to see examples of how datasets and lenses are created. Loading the sample data is also a good way to test that Platfora is working correctly with your configured Hadoop implementation. The Platfora server has a client load utility that you can run via the command-line to automatically load the sample data. This client utility creates four sample datasets and one sample lens in the Platfora web application...";
fil["749"]= "tutorial/model_tutorial_references.html@@@Model References and Events@@@A reference allows two datasets to be joined together on fields that they share in common. A reference creates a link in one dataset to the primary key of another dataset. An event is similar to a reference, except that the direction of the reference link is reversed. An event is created in a dataset that has a primary key and points to a foreign key field in another dataset...";
fil["750"]= "tutorial/tutorial_top.html@@@Getting Started Tutorial@@@The best way to learn a new product is by example. This tutorial walks you through the major features of Platfora using some sample data that comes with your Platfora server installation. After completing this tutorial, you should have a good understanding of how to create datasets, lenses, vizboards, and visualizations...";
fil["751"]= "user_account_profile/add_profile_picture.html@@@Add a User Profile Picture@@@Every user account in Platfora can be personalized with a profile picture. Your profile picture is used for your activity updates on the home page and also in your comment posts. If you don t supply your own picture, a default avatar icon is used...";
fil["752"]= "user_account_profile/change_own_password.html@@@Change Your User Password@@@If your Platfora user credentials are managed within Platfora, you can change your own user password from your user profile page. If your system administrator has configured Platfora to use an external LDAP server for authentication, then you would change your password in that external system, not in Platfor...";
fil["753"]= "user_account_profile/manage_user_profile.html@@@Manage Your Platfora User Profile@@@Your Platfora user profile is where you can view information associated with your Platfora user account, such as your system role, lens quota, and status updates on long-running operations such as lens builds and data exports. You can also update account information such as your profile picture or password...";
fil["754"]= "user_account_profile/tracked_notification_types.html@@@Activities that Generate Notifications@@@Some activities in Platfora, such as lens builds or data exports, run in the background and can take a while to finish. Other activities, such as comments made in a vizboards, may go unnoticed without some kind of notification. This topic lists the specific activities that are reported in your user profile notification list...";
fil["755"]= "user_account_profile/view_status_notifications.html@@@Manage Your Notifications@@@Platfora tracks and reports the status of certain activities, such as lens builds, and notifies you of status changes. You can view and manage these notifications in your user profile notification list, located in the top-right header of the Platfora application...";
